{"https://docs.nvidia.com/cuda/": "Installation Guides Programming Guides CUDA API References PTX Compiler API References Miscellaneous Tools White Papers Application Notes Compiler SDK Develop, Optimize and Deploy GPU-Accelerated Apps The NVIDIA\u00ae CUDA\u00ae Toolkit provides a development environment for creating high performance GPU-accelerated\r\napplications. With the CUDA Toolkit, you can develop, optimize, and deploy your applications on GPU-accelerated\r\nembedded systems, desktop workstations, enterprise data centers, cloud-based platforms and HPC supercomputers.\r\nThe toolkit includes GPU-accelerated libraries, debugging and optimization tools, a C/C++ compiler, and a runtime\r\nlibrary to deploy your application. Using built-in capabilities for distributing computations across multi-GPU configurations, scientists and researchers\r\ncan develop applications that scale from single GPU workstations to cloud installations with thousands of GPUs. The Release Notes for the CUDA Toolkit. The list of CUDA features by release. The CUDA Toolkit End User License Agreement applies to the NVIDIA CUDA Toolkit, the NVIDIA CUDA Samples, the NVIDIA Display Driver, NVIDIA Nsight tools (Visual Studio Edition), and the associated documentation on CUDA APIs, programming model and development tools. If you do not agree with the terms and conditions of the license agreement, then do not download or use the software. This guide provides the minimal first-steps instructions for installation and verifying CUDA on a standard system. This guide discusses how to install and check for correct operation of the CUDA Development Tools on Microsoft Windows systems. This guide discusses how to install and check for correct operation of the CUDA Development Tools on GNU/Linux systems. This guide provides a detailed discussion of the CUDA programming model and programming interface. It then describes the hardware implementation, and provides guidance on how to achieve maximum performance. The appendices include a list of all CUDA-enabled devices, detailed description of all extensions to the C++ language, listings of supported mathematical functions, C++ features supported in host and device code, details on texture fetching, technical specifications of various devices, and concludes by introducing the low-level driver API. This guide presents established parallelization and optimization techniques and explains coding metaphors and idioms that can greatly simplify programming for CUDA-capable GPU architectures. The intent is to provide guidelines for obtaining the best performance from NVIDIA GPUs using the CUDA Toolkit. This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on GPUs based on the NVIDIA Maxwell Architecture. This document provides guidance to ensure that your software applications are compatible with Maxwell. This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on GPUs based on the NVIDIA Pascal Architecture. This document provides guidance to ensure that your software applications are compatible with Pascal. This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on GPUs based on the NVIDIA Volta Architecture. This document provides guidance to ensure that your software applications are compatible with Volta. This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on GPUs based on the NVIDIA Turing Architecture. This document provides guidance to ensure that your software applications are compatible with Turing. This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on GPUs based on the NVIDIA Ampere GPU Architecture. This document provides guidance to ensure that your software applications are compatible with NVIDIA Ampere GPU architecture. This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on the Hopper GPUs. This document provides guidance to ensure that your software applications are compatible with Hopper architecture. This application note is intended to help developers ensure that their NVIDIA CUDA applications will run properly on the Ada GPUs. This document provides guidance to ensure that your software applications are compatible with Ada architecture. Maxwell is NVIDIA\u2019s 4th-generation architecture for CUDA compute applications. Applications that follow the best practices for the Kepler architecture should typically see speedups on the Maxwell architecture without any code changes. This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Maxwell architectural features. Pascal is NVIDIA\u2019s 5th-generation architecture for CUDA compute applications. Applications that follow the best practices for the Maxwell architecture should typically see speedups on the Pascal architecture without any code changes. This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Pascal architectural features. Volta is NVIDIA\u2019s 6th-generation architecture for CUDA compute applications. Applications that follow the best practices for the Pascal architecture should typically see speedups on the Volta architecture without any code changes. This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Volta architectural features. Turing is NVIDIA\u2019s 7th-generation architecture for CUDA compute applications. Applications that follow the best practices for the Pascal architecture should typically see speedups on the Turing architecture without any code changes. This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Turing architectural features. NVIDIA Ampere GPU Architecture is NVIDIA\u2019s 8th-generation architecture for CUDA compute applications. Applications that follow the best practices for the NVIDIA Volta architecture should typically see speedups on the NVIDIA Ampere GPU Architecture without any code changes. This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging NVIDIA Ampere GPU Architecture\u2019s features. Hopper GPU Architecture is NVIDIA\u2019s 9th-generation architecture for CUDA compute applications. Applications that follow the best practices for the NVIDIA Volta architecture should typically see speedups on the Hopper GPU Architecture without any code changes. This guide summarizes the ways that applications can be fine-tuned to gain additional speedups by leveraging Hopper GPU Architecture\u2019s features. The NVIDIA\u00ae Ada GPU architecture is NVIDIA\u2019s latest architecture for CUDA\u00ae compute applications. The NVIDIA Ada GPU architecture retains and extends the same CUDA programming model provided by previous NVIDIA GPU architectures such as NVIDIA Ampere and Turing, and applications that follow the best practices for those architectures should typically see speedups on the NVIDIA Ada architecture without any code changes. This guide summarizes the ways that an application can be fine-tuned to gain additional speedups by leveraging the NVIDIA Ada GPU architecture\u2019s features. This guide provides detailed instructions on the use of PTX, a low-level parallel thread execution virtual machine and instruction set architecture (ISA). PTX exposes the GPU as a data-parallel computing device. NVIDIA Video Decoder (NVCUVID) is deprecated. Instead, use the NVIDIA Video Codec SDK (https://developer.nvidia.com/nvidia-video-codec-sdk). This document shows how to write PTX that is ABI-compliant and interoperable with other CUDA code. This document shows how to inline PTX (parallel thread execution) assembly language statements into CUDA code. It describes available assembler statement parameters and constraints, and the document also provides a list of some pitfalls that you may encounter. Fields in structures might appear in order that is different from the order of declaration. Fields in structures might appear in order that is different from the order of declaration. The CUDA math API. The cuBLAS library is an implementation of BLAS (Basic Linear Algebra Subprograms) on top of the NVIDIA CUDA runtime. It allows the user to access the computational resources of NVIDIA Graphical Processing Unit (GPU), but does not auto-parallelize across multiple GPUs. The cuDLA API. The NVBLAS library is a multi-GPUs accelerated drop-in BLAS (Basic Linear Algebra Subprograms) built on top of the NVIDIA cuBLAS Library. The nvJPEG Library provides high-performance GPU accelerated JPEG decoding functionality for image formats commonly used in deep learning and hyperscale multimedia applications. The cuFFT library user guide. The user guide for CUB. The API reference for libcu++, the CUDA C++ standard library. The NVIDIA\u00ae GPUDirect\u00ae Storage cuFile API Reference Guide provides information about the preliminary version of the cuFile API reference guide that is used in applications and frameworks to leverage GDS technology and describes the intent, context, and operation of those APIs, which are part of the GDS technology. The cuRAND library user guide. The cuSPARSE library user guide. NVIDIA NPP is a library of functions for performing CUDA accelerated processing. The initial set of functionality in the library focuses on imaging and video processing and is widely applicable for developers in these areas. NPP will evolve over time to encompass more of the compute heavy tasks in a variety of problem domains. The NPP library is written to maximize flexibility, while maintaining high performance. The user guide for the nvJitLink library. The user guide for the nvFatbin library. NVRTC is a runtime compilation library for CUDA C++. It accepts CUDA C++ source code in character string form and creates handles that can be used to obtain the PTX. The PTX string generated by NVRTC can be loaded by cuModuleLoadData and cuModuleLoadDataEx, and linked with other modules by cuLinkAddData of the CUDA Driver API. This facility can often provide optimizations and performance not possible in a purely offline static compilation. The C++ parallel algorithms library. The cuSOLVER library user guide. This guide shows how to compile a PTX program into GPU assembly code using APIs provided by the static PTX Compiler library. This document describes the demo applications shipped with the CUDA Demo Suite. This guide is intended to help users get started with using NVIDIA CUDA on Windows Subsystem for Linux (WSL 2). The guide covers installation and running CUDA applications and containers in this environment. This edition of the user guide describes the Multi-Instance GPU feature of the NVIDIA\u00ae A100 GPU. This document describes CUDA Compatibility, including CUDA Enhanced Compatibility and CUDA Forward Compatible Upgrade. The CUPTI-API. The CUDA Profiling Tools Interface (CUPTI) enables the creation of profiling and tracing tools that target CUDA applications. The CUDA debugger API. A technology introduced in Kepler-class GPUs and CUDA 5.0, enabling a direct path for communication between the GPU and a third-party peer device on the PCI Express bus when the devices share the same upstream root complex using standard features of PCI Express. This document introduces the technology and describes the steps necessary to enable a GPUDirect RDMA connection to NVIDIA GPUs within the Linux device driver model. The documentation for GPUDirect Storage. vGPUs that support CUDA. This is a reference document for nvcc, the CUDA compiler driver. nvcc accepts a range of conventional compiler options, such as for defining macros and include/library paths, and for steering the compilation process. The NVIDIA tool for debugging CUDA applications running on Linux and QNX, providing developers with a mechanism for debugging CUDA applications running on actual hardware. CUDA-GDB is an extension to the x86-64 port of GDB, the GNU Project debugger. The user guide for Compute Sanitizer. Nsight Eclipse Plugins Installation Guide Nsight Eclipse Plugins Edition getting started guide The documentation for Nsight Systems. The NVIDIA Nsight Compute is the next-generation interactive kernel profiler for CUDA applications. It provides detailed performance metrics and API debugging via a user interface and command line tool. The documentation for Nsight Visual Studio Edition. This is the guide to the Profiler. The application notes for cuobjdump, nvdisasm, and nvprune. A number of issues related to floating point accuracy and compliance are a frequent source of confusion on both CPUs and GPUs. The purpose of this white paper is to discuss the most common issues related to NVIDIA GPUs and to supplement the documentation in the CUDA C++ Programming Guide. In this white paper we show how to use the cuSPARSE and cuBLAS libraries to achieve a 2x speedup over CPU in the incomplete-LU and Cholesky preconditioned iterative methods. We focus on the Bi-Conjugate Gradient Stabilized and Conjugate Gradient iterative methods, that can be used to solve large sparse nonsymmetric and symmetric positive definite linear systems, respectively. Also, we comment on the parallel sparse triangular solve, which is an essential building block in these algorithms. This application note provides an overview of NVIDIA\u00ae Tegra\u00ae memory architecture and considerations for porting code from a discrete GPU (dGPU) attached to an x86 system to the Tegra\u00ae integrated GPU (iGPU). It also discusses EGL interoperability. The libNVVM API. The libdevice library is an LLVM bitcode library that implements common functions for GPU kernels. NVVM IR is a compiler IR (intermediate representation) based on the LLVM IR. The NVVM IR is designed to represent GPU compute kernels (for example, CUDA kernels). High-level language front-ends, like the CUDA C compiler front-end, can generate NVVM IR. \nPrivacy Policy\r\n|\r\nManage My Privacy\r\n|\r\nDo Not Sell or Share My Data\r\n|\r\nTerms of Service\r\n|\r\nAccessibility\r\n|\r\nCorporate Policies\r\n|\r\nProduct Security\r\n|\r\nContact\n \u00a9 Copyright 2007-2024, NVIDIA Corporation & affiliates. All rights reserved.\r\n      Last updated on Jul 1, 2024.\r\n      ", "https://developer.nvidia.com/nvidia-video-codec-sdk": "A comprehensive set of APIs including high-performance tools, samples and documentation for hardware accelerated video encode and decode on Windows and Linux. \nNVIDIA GeForce Now is made possible by leveraging NVENC in the datacenter and streaming the result to end clients\r\n\t\t NVIDIA GPUs contain one or more hardware-based decoder and encoder(s) (separate from the CUDA cores) which provides fully-accelerated hardware-based video decoding and encoding for several popular codecs. With decoding/encoding offloaded, the graphics engine and the CPU are free for other operations. GPU hardware accelerator engines for video decoding (referred to as NVDEC) and video encoding (referred to as NVENC) support faster than real-time video processing which makes them suitable to be used for transcoding applications, in addition to video playback. Video Codec SDK lets you harness NVENC and NVDEC for real-time 8k 60FPS AV1 and HEVC video on Ada Lovelace architecture. Introducing AV1 encoding with Video Codec SDK 12.0 on NVIDIA\u2019s Ada architecture. AV1 is the state of the art video coding format that supports higher quality with better performance compared to H.264 and HEVC. On Ada, multiple NVENC coupled with AV1 enables encoding 8k video at 60fps alongside a higher number of concurrent sessions. With complete encoding (which is computationally complex) offloaded to NVENC, the graphics engine and the CPU are free for other operations. For example, in a game recording and streaming scenario like streaming to Twitch.tv using Open Broadcaster Software (OBS), encoding being completely offloaded to NVENC makes the graphics engine bandwidth fully available for game rendering. NVENC enables streaming applications at high quality and ultra-low latency without utilizing the CPU, encoding at very high quality for archiving, OTT streaming, web videos, and encoding with ultra-low power consumption per stream (Watts/stream) Note: These graphs showcases performance on NVIDIA datacenter T4,  A10 and L40. Bitrate savings are BD-BR based on PSNR, average across a large variety of content (several hundreds of video clips), using FFmpeg. Only datacenter GPUs are presented on the benchmark graphs for clarity but equivalent workstation GPU with same architecture performs similarly\u200b. To learn more about the hardware details, the process and software configuration used for generating above data, please refer to this detailed documentation\u200b. * Except GM108 and GP108 (not supported) ** Except GP100 (is limited to 4K resolution) NVIDIA GPUs contain a hardware-based decoder (referred to as NVDEC) which provides fully-accelerated hardware-based video decoding for several popular codecs. With complete decoding offloaded to NVDEC the graphics engine and the CPU are free for other operations. NVDEC supports much faster than real-time decoding which makes it suitable to be used for transcoding applications, in addition to video playback applications. NVDECODE API enables software developers to configure this dedicated hardware video decoder. This dedicated accelerator supports hardware-accelerated decoding of the following video codecs on Windows and Linux platforms: MPEG-2, VC-1, H.264 (AVCHD), H.265 (HEVC), VP8, VP9 and AV1 (see table below for codec support for each GPU generation). * Except GM108 (not supported) ** Max resolution support is limited to selected Pascal chips *** VP8 decode support is limited to selected Pascal chips **** VP9 10/12 bit decode support is limited to select Pascal chips NVIDIA has provided hardware-accelerated video processing on GPUs for over a decade through the NVIDIA Video Codec SDK. This is a comprehensive set of APIs, high-performance tools, samples, and documentation for hardware-accelerated video encode and decode on Windows and Linux. \r\n\t   NVIDIA also supports GPU-accelerated encode and decode through Microsoft\u2019s DirectX Video, a cross-vendor API for Windows developers and Vulkan Video which has both Linux and Windows support. In contrast to the NVIDIA Video Codec SDK, both DirectX Video and Vulkan Video are low-level APIs. While the Video Codec SDK provides automation for C++ developers, DirectX Video and Vulkan Video provide precise control over video streaming through hardware acceleration blocks, empowering applications to efficiently orchestrate system resources. \r\n\t   Whether you prefer DirectX or Vulkan, you can combine flexible GPU-accelerated video encoding and decoding with other GPU acceleration, like 3D and AI, using the language of your choice.\r\n\t   The low-level Vulkan Video extensions are also attractive to developers of popular open-source streaming media frameworks such as GStreamer and FFmpeg both of which are being actively ported to Vulkan Video. The cross-platform availability of Vulkan will enable accelerated GPU processing for these frameworks across multiple platforms without needing to port to multiple proprietary video APIs. Please refer to the Vulkan Video getting started page for more details. PyNvVideoCodec is another set of APIs introduced in Q4 2023, which provides simple APIs for harnessing video encoding and decoding capabilities when working with videos in Python. PyNvVideoCodec is a library that provides python bindings over C++ APIs for hardware accelerated video encoding and decoding. Video Codec SDK, DirectX Video, Vulkan Video and PyNvVideoCodec provide complementary support to GPU-accelerated video workflows. NVIDIA will continue to support all listed APIs providing developers with the option to use the ones that best suit their needs. Premiere Pro is the industry-leading video editing\r\n\t\t\tapplication for film, TV, social, and online content.\r\n\t\t\t\r\n\t\t\t  Learn\r\n\t\t\t  More\r\n\t\t\t Blackmagic is a leading manufacturer of creative video technology. Dedicated to quality and stability; Blackmagic is world famous for their codecs and affordable high-end quality editing workstations built upon Blackmagic software and hardware. \nVisit\r\n\t\t\t\t  Blackmagic for detailed product information\n Comprimato is a JPEG2000 software codec\r\n\t\t\t  toolkit offering media & entertainment and geospatial imaging\r\n\t\t\t  technology company\u2019s life-like viewing experience that result in\r\n\t\t\t  better enjoyment and more accurate decision-making. The JPEG2000\r\n\t\t\t  standard compliant Ultra HD software codec leverages the\r\n\t\t\t  supercomputing power of GPUs and CPUs to speed up video and image\r\n\t\t\t  compression by 10x. The codec saves infrastructure costs by 70%,\r\n\t\t\t  reducing development cycles by 50% and enabling new revenue streams\r\n\t\t\t  such as Ultra HD, High Dynamic Range (HDR) and High Frame Rate (HFR)\r\n\t\t\t  video. Visit Comprimato\r\n\t\t\t\tfor detailed product information DELTACAST develops state-of-the-art products for the professional TV broadcast market, providing a range of cost-effective video cards that, with the SDK software, can be used in OEM products to create professional broadcast custom solutions and products. Visit DELTACAST for detailed product information Erlyvideo LLC has been developing software for streaming video since 2010. Our carrier-grade server solutions help business clients capture, process, transcode, archive, and deliver video to millions of subscribers. We are making every effort to research and develop reliable, premium quality products that truly meet customer needs. Customers in more than 100 countries use our products for building IPTV/OTT, CDN, and Video Surveillance as a Service CCTV systems. Flussonic Media Server is a multi-purpose software solution for launching high load video streaming services. Using Flussonic Media Server you can set up an end-to-end video streaming pipeline of any scale. Flussonic can ingress and egress videos in almost any format, codec, and resolution. It will process and transcode incoming streams and deliver beautiful video to your subscribers. Let your business benefit from the most advanced and efficient video streaming platform. Visit Flussonic.com for detailed product information Gcore  accelerates AI training, provides comprehensive cloud services, improves content delivery, and protects servers and applications. Visit Gcore for detailed product information ((https://gcore.com/) Fastvideo is a world leader in the field of high performance GPU-based image and video processing. Fastvideo team consists of experienced and highly dedicated professionals and it focuses on GPU image processing, algorithm design and parallel computations. Our technologies show unmatched performance in image compression and decompression (JPEG, JPEG2000, Raw Bayer), demosaicing, denoising, tone mapping, color correction, resizing, sharpening, encoding and decoding of video streams in various applications including image and video processing, high speed imaging, machine vision and other camera applications, streaming, digital cinema, 3D and VR, broadcasting, etc. Visit Fastvideo for detailed product information MainConcept has been the premier provider of video and audio codecs, plugins and applications to the production, streaming and broadcast industries for three decades. As the technology of choice for some of the most valued brands across the globe, MainConcept supports robust video workflows from ingest through delivery. The MainConcept\u00ae Hybrid GPU HEVC Encoder combines the market-leading MainConcept\u00ae HEVC software encoder with the unrivaled performance of NVIDIA RTX architecture, bridging the gap between high-quality software and fast-performing hardware encoding. Leveraging MainConcept\u2019s reliable, market-proven algorithms for rate control and quality encoding with the processing power of NVIDIA, the MainConcept Hybrid GPU HEVC Encoder gives you best-in-class image quality (up to 8K) at tremendous speed. \"Enabling access to HEVC/H.265 video encoding in hardware allows our customers to continue working in the well-known MainConcept environment with its rich portfolio of multiplexers and auxiliary components, while benefiting from the computational power of NVIDIA GPUs. Using NVIDIA GPUs for HEVC/H.265 encoding increases server density for processing multiple video streams on one system while still having enough CPU cycles available for applications.\" Deacon Johnson, SVP Global Sales - Technology Licensing for MainConcept Learn more about MainConcept Hybrid GPU HEVC Encoder Medialooks, founded in 2005, provides broadcast customers with a high-level software development kit to quickly build playout automation, virtual studio and video capture solutions. Customers include PlayBox Technologies, Arvato Systems, Masterplay, Winjay, Etere, Axel Technology, Xeus Media, Wolftech and Broadcast Play. Visit Medialooks for detailed product information Multicamera.Systems LLC is a developer of video acquisition and recording software for machine vision cameras, catering for variety of industries: science labs, VR, sport analytics autonomous cars and military. \"The Recorder\" software is the only software on the market capable of recording h.26x compressed video at thousands of frames per second thanks to our own \"GPUSqueeze\" library supporting multi-GPU video compression. This library is now available for third party developers. \"The Recorder\" software major features: \"GPUSqueeze\" library major features: Visit Multicamera.systems for more information on the \"GPUSqueeze\" library Visit Medialooks for detailed product information on \"The Recorder\" software Norpix is a developer of digital video recording software for scientific, machine vision, military and general purpose digital video acquisition applications. We market the industries number 1 DVR software Streampix for single or multiple camera acquisition. We also develop an SDK and CUDA JPEG compression library that runs on NVIDIA GPU\u2019s. Benefit of the product: Visit Norpix for detailed product information NVIDIA GeForce NOW\u2122 is an on-demand service that connects you to NVIDIA\u2019s cloud-gaming supercomputers to stream PC games to your SHIELD device at up to 1080p resolution and 60 frames per second. Learn more about GeForce NOW OBS Studio is a free and open source software designed for capturing, compositing, encoding, recording, and live streaming video content, efficiently. Learn more about OBS Studio BLOG - New GeForce-Optimized OBS and RTX Encoder Enables Pro-Quality Broadcasting on a Single PC Based in Hong Kong and with a development center in Manila, Philippines. More than 8 Million people and businesses use SplitmediaLabs products to grow their communities, create innovative content and connect with other players from around the world. SplitmediaLabs has helped usher in the new age of live streaming gameplay since its creation back in 2009 and is the developer XSplit, Challonge and Player.me. XSplit Broadcaster: A simple yet powerful live streaming software and recording software that powers countless live streams and recordings around the world. XSplit Broadcaster is the perfect solution for producing and delivering rich video content. Learn more about XSplit Streamline is a reference system design for a premium quality, white label, end to end live streaming system from HDMI / HD-SDI capture all the way to a player on a CDN that works on web, iOS, and Android devices. Using commodity computer hardware, free software, and AWS, it\u2019s an affordable way to learn how to build a very high quality live streaming system. Learn more about Streamline Telestream\u00ae specializes in products that make it possible to get video content to any audience regardless of how it is created, distributed or viewed. Throughout the entire digital media lifecycle, from capture to viewing, for consumers through high-end professionals, Telestream products range from desktop components and cross-platform applications to fully-automated, enterprise-class digital media transcoding and workflow systems. Telestream enables users in a broad range of business environments to leverage the value of their video content. Visit Telestream for detailed product information Wowza Media Systems\u2122 is the recognized gold standard of streaming, with more than 22,000 customers in 170+ countries. By reducing the complexities of video and audio delivery to any device, Wowza\u2122 enables organizations to expand their reach and more deeply engage their audiences, in industries ranging from education to broadcasting. Service providers, direct customers and partners worldwide trust Wowza products to provide robust, customizable and scalable streaming solutions\u2014with powerful APIs and SDKs to meet organizations\u2019 evolving streaming needs. Wowza was founded in 2005, is privately held, and is headquartered in Colorado. Visit Wowza for detailed product information Beamr (NASDAQ:BMR) is a video technology and image science software company. Beamr is a leading provider of video encoding, transcoding, and optimization software solutions that enable high quality, performance, and bitrate efficiency for Live and VOD video services. \r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tSince 2021 Beamr and Nvidia have been working together to port Beamr's Content Adaptive BitRate (CABR) and seamlessly integrate it with Nvidia's NVENC video encoder to create an accelerated video optimization solution. This guarantees the highest video quality at the lowest bitrate possible and is available to all NVENC encoders.\r\n\t\t\r\n\t\t\r\n\t\t\r\n\t\tIn Oct 2023 Beamr launched a cloud service running over Nvidia's NVENC with the vision of democratizing videooptimization at large scale.\r\n\t\t\r\n\t\t Learn more about Beamr Video Codec SDK 12.1 is available now, bringing improvements to split encoding and a new low-level NVENC API. Learn about the new features and how they have been used to accelerate video creation and streaming.  AV1 is the new gold standard video format, with superior efficiency and quality compared to older H.264 and H.265 formats. It is the most recent royalty-free, efficient video encoder standardized by the Alliance for Open Media.  Updates to Video Codec SDK, including AV1 encoding on the new Ada GPU generation and updates to Optical Flow SDK, including the new frame rate up conversion library, are announced at GTC. NVIDIA GPUs contain dedicated hardware for video encoding, decoding, JPEG sill image decoding and optical flow computation. This talk covers latest features supported by Ada GPUs as well as software updates such as new SDK features, use-cases etc.\r\n\t\t\t\t With NVIDIA encoder acceleration in Adobe Premiere Pro, editors can export high-resolution videos up to 5x faster than on CPU. Q&A style sessions  provide an overview of the  two SDKs including new features and enhancements, provide tips for efficient use, and address any open questions from developers. Get Started Developing with Video Codec SDK.    ", "https://nvlabs.github.io/cub/": "", "https://nvidia.github.io/libcudacxx/": "", "https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html": " \n  \n       \n       The NVIDIA\u00ae GPUDirect\u00ae Storage cuFile API Reference Guide provides information about the cuFile API reference that is used in applications and frameworks to leverage GDS technology and describes the intent, context, and operation of those APIs, which are part of the GDS technology.  \n  \n       \n       \n       NVIDIA\u00ae Magnum IO GPUDirect\u00ae Storage (GDS) is part of the GPUDirect family. GDS enables a direct data path for direct memory access (DMA) transfers between GPU memory and storage, which avoids a bounce buffer through the CPU. This direct path increases system bandwidth and decreases the latency and utilization load on the CPU.   This document provides information about the cuFile APIs that are used in applications and frameworks to leverage GDS technology and describes the intent, context, and operation of those APIs which are part of the GDS technology.  \n        \n         \n          The APIs and descriptions are subject to change without notice. \n         \n  \n       \n       \n       This section describes the operation of the cuFile APIs.  Because the functionality is part of the CUDA Driver C API, the APIs use the cuFile prefix and camel case motif of the CUDA Driver.  \n        \n \n          Starting from CUDA toolkit 12.2 (GDS version 1.7.x) release cuFile APIs support memory allocated on GPU device as well as host memory. peer to peer transfer using GPUDirect\u2122 is supported to and from device memory on supported file system and hardware configurations. The APIs will refer to this memory address as buffer pointer unless the API specifically applies to a particular type of memory. \n         \n  \n  \n        \n        The following describes the dynamic interactions between the cuFile APIs.  Some of the cuFile APIs are optional. If they are not called proactively, their actions will occur reactively:  \n          If cuFile{DriverOpen, HandleRegister, BufRegister} is called on a driver, file, or buffer, respectively that has been opened or registered by a previous cuFile* API call, this will result in an error. Calling cuFile{BufDeregister, HandleDeregister, DriverClose} on a buffer, file, or driver, respectively that has never been opened or registered by a previous cuFile* API call results in an error. For these errors, the output parameters of the APIs are left in an undefined state, and there are no other side effects.  \n          cuFileDriverOpen explicitly causes driver initialization.  Its use is optional. If it is not used, driver initialization happens implicitly at the first use of the cuFile{HandleRegister, Read, Write, BufRegister} APIs.   cuFileBufRegister explicitly registers a memory buffer.  If this API is not called, an internal registered memory is used if required on the first time the buffer is used, for example, in cuFile{Read, Write}.   cuFile{BufDeregister, HandleDeregister} explicitly frees a buffer and file resources, respectively.  If this API is not called, the buffer and resources are implicitly freed when the driver is closed using cuFileDriverClose.   cuFileDriverClose explicitly frees driver resources.  If this API is not called, the driver resources are implicitly freed when dlclose() is performed on the library handle or when the process is terminated.  \n \n  \n        \n        This section describes the overall workflow to manage the driver, the file, and buffer management:  Not using cuFileBufRegister might not be performant for small IO sizes.  Refer to the GPUDirect Best Practices Guide for more information.  \n \n           Not using the cuFileDeregister and cuFileDriverClose APIs (steps 5, 6, and 7) might unnecessarily consume resources, as shown by tools such as valgrind. The best practice is to always call these APIs in the application cleanup paths. \n          \n \n \n  Use Cases \n        \n         cuFile APIs can be used in different scenarios: \n           Note: If the option is \u201cfalse\u201d, this option will override and disable any filesystem-specific option to enable RDMA writes.  If true, forces compatibility mode to be used for writes where the file offset and/or IO size is not aligned to Page Boundary (4KB).  For a lustre filesystem, if greater than 0, compatibility mode is used for IO sizes between [1 - posix_gds_min_kb] specified in kB.  Note: This option will force posix mode even if \u201callow_compat_mode\u201d is set to \u201cfalse\u201d.  If this option is false, all writes to WekaFS will use compatibility mode.  Note: If the option is set to \u201cfalse\u201d, cuFile library will use the posix path even if the allow_compat_mode option is true or false.   If this option is false, all writes to IBM Spectrum Scale will use compatibility mode.  Note: If the option is set to \u201cfalse\u201d, cuFile library will use the posix path even if the allow_compat_mode option is true or false.  \n\"rdma_dynamic_routing\": false, \n\"rdma_dynamic_routing_order\": [ \" \"SYS_MEM\" ]  For wekaFS or IBM Spectrum Scale mounts: If there are no rdma_dev_addr_list specified, or failure to register MR with ib device.   Limitations\n \n  \n       \n       \n       This section provides information about the cuFile APIs that are used from the CPU to enable applications and frameworks.  \n \n \n \n  \n         \n         Here are the relevant cuFile enums and their descriptions. typedef struct CUfileError {\n        CUfileOpError err; // cufile error\n        enum CUresult cu_err; // for CUDA-specific errors\n} CUfileError_t;\n\n/**\n * error macros to inspect error status of type CUfileOpError\n */\n \n#define IS_CUFILE_ERR(err) \\\n        (abs((err)) > CUFILEOP_BASE_ERR)\n \n#define CUFILE_ERRSTR(err) \\\n        cufileop_status_error(static_cast<CUfileOpError>(abs((err))))\n \n#define IS_CUDA_ERR(status) \\\n        ((status).err == CU_FILE_CUDA_DRIVER_ERROR)\n \n#define CU_FILE_CUDA_ERR(status) ((status).cu_ \n  The following enum and two structures enable broader cross-OS support:\n          enum CUfileFileHandleType { \n    CU_FILE_HANDLE_TYPE_OPAQUE_FD = 1, /* linux based fd    */\n    CU_FILE_HANDLE_TYPE_OPAQUE_WIN32 = 2, /* windows based handle */\nCU_FILE_HANDLE_TYPE_USERSPACE_FS  = 3, /* userspace based FS */\n}; \n \ntypedef struct CUfileDescr_t {\nCUfileFileHandleType type; /* type of file being registered */\nunion { \nint fd;             /* Linux   */\nvoid *handle;         /* Windows */\n} handle;\nconst CUfileFSOps_t *fs_ops;     /* file system operation table */ \n}CUfileDescr_t;\n \n/* cuFile handle type */\ntypedef void*  CUfileHandle_t;\n \ntypedef struct cufileRDMAInfo\n{\n        int version;\n        int desc_len;\n        const char *desc_str;\n}cufileRDMAInfo_t;\n \ntypedef struct CUfileFSOps {\n      /* NULL means discover using fstat */\n      const char* (*fs_type) (void *handle);\n \n      /* list of host addresses to use,  NULL means no restriction */\n      int (*getRDMADeviceList)(void *handle, sockaddr_t **hostaddrs);\n \n      /* -1 no pref */\n      int (*getRDMADevicePriority)(void *handle, char*, size_t,\n                                loff_t, sockaddr_t* hostaddr);\n \n      /* NULL means try VFS */\n      ssize_t (*read) (void *handle, char*, size_t, loff_t, cufileRDMAInfo_t*);\n      ssize_t (*write) (void *handle, const char *, size_t, loff_t , cufileRDMAInfo_t*);\n}CUfileFSOps_t;\n\ntypedef enum CUfileDriverStatusFlags {\n        CU_FILE_LUSTRE_SUPPORTED = 0,        /*!< Support for DDN LUSTRE */\n        CU_FILE_WEKAFS_SUPPORTED = 1,        /*!< Support for WEKAFS */\n        CU_FILE_NFS_SUPPORTED = 2,           /*!< Support for NFS */\n        CU_FILE_GPFS_SUPPORTED = 3,          /*! < Support for GPFS */\n        CU_FILE_NVME_SUPPORTED = 4,          /*!< Support for NVMe */\n        CU_FILE_NVMEOF_SUPPORTED = 5,        /*!< Support for NVMeOF */\n        CU_FILE_SCSI_SUPPORTED = 6,          /*!< Support for SCSI */\n        CU_FILE_SCALEFLUX_CSD_SUPPORTED = 7, /*!< Support for Scaleflux CSD*/\n        CU_FILE_NVMESH_SUPPORTED = 8,        /*!< Support for NVMesh Block Dev*/\n        CU_FILE_BEEGFS_SUPPORTED = 9,        /*!< Support for BeeGFS */\n}CUfileDriverStatusFlags_t;\n\n \nenum CUfileDriverControlFlags {\n      CU_FILE_USE_POLL_MODE = 0, /*!< use POLL mode. properties.use_poll_mode*/\n      CU_FILE_ALLOW_COMPAT_MODE = 1 /*!< allow COMPATIBILITY mode. properties.allow_compat_mode*/\n};\n \ntypedef enum CUfileFeatureFlags {\n    CU_FILE_DYN_ROUTING_SUPPORTED =0,\n    CU_FILE_BATCH_IO_SUPPORTED = 1,\n    CU_FILE_STREAMS_SUPPORTED = 2\n} CUfileFeatureFlags_t;;\n \n/* cuFileDriverGetProperties describes this structure\u2019s members */\ntypedef struct CUfileDrvProps {\n   struct {\n     unsigned int major_version;\n     unsigned int minor_version;\n     size_t poll_thresh_size;\n     size_t max_direct_io_size;\n     unsigned int dstatusflags;\n     unsigned int dcontrolflags;\n   } nvfs;\n   CUfileFeatureFlags_t fflags;\n   unsigned int max_device_cache_size;\n   unsigned int per_buffer_cache_size;\n   unsigned int max_pinned_memory_size;\n   unsigned int max_batch_io_timeout_msecs;\n}CUfileDrvProps_t;\n\n/* Parameter block for async cuFile IO */ \n/* Batch APIs use an array of these    */\n/* Status must be CU_FILE_WAITING when submitted, and is\n   updated when enqueued and when complete, so this user-allocated\n   structure is live until the operation completes.    */\ntypedef enum CUFILEStatus_enum {\n        CUFILE_WAITING = 0x000001,  /* required value prior to submission */\n        CUFILE_PENDING = 0x000002,  /* once enqueued */\n        CUFILE_INVALID = 0x000004,  /* request was ill-formed or could not be enqueued */\n        CUFILE_CANCELED = 0x000008, /* request successfully canceled */\n        CUFILE_COMPLETE = 0x0000010, /* request successfully completed */\n        CUFILE_TIMEOUT = 0x0000020,  /* request timed out */\n        CUFILE_FAILED  = 0x0000040  /* unable to complete */\n}CUfileStatus_t;\n\ntypedef enum cufileBatchMode {\n        CUFILE_BATCH = 1,\n} CUfileBatchMode_t;\n \ntypedef struct CUfileIOParams {\n        CUfileBatchMode_t mode; // Must be the very first field.\n        union {\n                struct  {\n                        void *devPtr_base;\n                        off_t file_offset;\n                        off_t devPtr_offset;\n                        size_t size;\n                }batch;\n        }u;\n        CUfileHandle_t fh;\n        CUfileOpcode_t opcode;\n        void *cookie;\n}CUfileIOParams_t;\n \ntypedef struct CUfileIOEvents {\n        void *cookie;\n        CUfileStatus_t   status;      /* status of the operation */\n        size_t ret;       /* -ve error or amount of I/O done. */\n}CUfileIOEvents_t; \n  \n  \n         \n         cuFile typedefs: \n typedef struct CUfileDescr CUfileDesr_t\ntypedef struct CUfileError CUfileError_t\ntypedef struct CUfileDrvProps CUfileDrvProps_t\ntypedef enum CUfileFeatureFlags CUfileFeatureFlags_t\ntypedef enum CUfileDriverStatusFlags_enum CUfileDriverStatusFlags_t\ntypedef enum CUfileDriverControlFlags_enum CUfileDriverControlFlags_t\ntypedef struct CUfileIOParams CUfileIOParams_t\ntypedef enum CUfileBatchOpcode CUfileBatchOpcode_t \n  \n  \n         \n         cuFile enums: This is the cuFile operation code for batch mode.    /* cuFile Batch IO operation kind */\nenum CUfileOpcode { \n     CU_FILE_READ,\n     CU_FILE_WRITE,\n};  The cuFile Status codes for batch mode.     These values cannot have any side effects on the file system, the application process, and the larger system.  \n               cuFile-specific errors will be greater than CUFILEOP_BASE_ERR to enable users to distinguish between POSIX errors and cuFile errors.\n               #define CUFILEOP_BASE_ERR 5000 \n    A CUDA Driver API error.  This error indicates a CUDA driver-api error. If this is set, a CUDA-specific error code is set in the cu_err field for cuFileError.   \n             Data path errors are captured via standard error codes by using errno. The APIs will return -1 on error. \n              \n  \n  \n        \n        The following cuFile APIs that are used to initialize, finalize, query, and tune settings for the cuFile system.  \n /* Initialize the cuFile infrastructure */\nCUfileError_t cuFileDriverOpen();  \n\n/* Finalize the cuFile system */\nCUfileError_t cuFileDriverClose();\n\n/* Query capabilities based on current versions, installed functionality */\nCUfileError_t cuFileGetDriverProperties(CUfileDrvProps_t *props);\n\n/*API to set whether the Read/Write APIs use polling to do IO operations */\nCUfileError_t cuFileDriverSetPollMode(bool poll, size_t poll_threshold_size);\n\n/*API to set max IO size(KB) used by the library to talk to nvidia-fs driver */\nCUfileError_t cuFileDriverSetMaxDirectIOSize(size_t max_direct_io_size);\n\n/* API to set maximum GPU memory reserved per device by the library for internal buffering */\nCUfileError_t cuFileDriverSetMaxCacheSize(size_t max_cache_size);\n\n/* Sets maximum buffer space that is pinned in KB for use by  cuFileBufRegister\nCUfileError_t cuFileDriverSetMaxPinnedMemSize(size_t\n   max_pinned_memory_size); \n\n \n          Refer to sample_007 for usage. \n         \n  \n  \n        \n        The core of the cuFile IO APIs are the read and write functions. \n ssize_t cuFileRead(CUFileHandle_t fh, void *bufPtr_base, size_t size, off_t file_offset, off_t devPtr_offset);\nssize_t cuFileWrite(CUFileHandle_t fh, const void *bufPtr_base, size_t size, off_t file_offset, off_t devPtr_offset); \n \n        \n         The starting offset of the buffer on the device or host is determined by a base (bufPtr_base) and offset (bufPtr_offset). This offset is distinct from the offset in the file. \n          \n           To use the registered buffer, the bufPtr_base must be the buffer pointer used to register during cuFileBufRegister. Otherwise cuFileRead and cuFileWrite APIs may use internal memory buffers for GPUDirect Storage peer to peer operations. \n          \n\n \n          The default behavior for all paths where GDS is not supported is for the cuFile IO API to attempt IO using file system supported posix mode APIs when properties.allow_compat_mode is set to true. In order to disable cuFile APIs falling back to posix APIs for unsupported GDS paths, properties.allow_compat_mode in the /etc/cufile.json file should be set to false. \n         \n \n          Refer to sample sample_003 for usage. \n         \n  \n  \n        \n        Here is some information about the cuFile Handle APIs.  The cuFileHandleRegister API makes a file descriptor or handle that is known to the cuFile subsystem by using an OS-agnostic interface. The API returns an opaque handle that is owned by the cuFile subsystem.  \n          To conserve memory, the cuFileHandleDeregister API is used to release cuFile-related memory objects. Using only the POSIX close will not clean up resources that were used by cuFile. Additionally, the clean up of cuFile objects associated with the files that were operated on in the cuFile context will occur at cuFileDriverClose.  \n        \n          CUfileError_t cuFileHandleRegister(CUFileHandle_t *fh, CUFileDescr_t *descr);\nvoid cuFileHandleDeregister(CUFileHandle_t fh); \n\n \n          Refer to sample_003 for usage. \n         \n  \n  \n        \n        The cuFileBufRegister API incurs a significant performance cost, so registration costs should be amortized where possible. Developers must ensure that buffers are registered up front and off the critical path.   The cuFileBufRegister API is optional. If this is not used, instead of pinning the user\u2019s memory, cuFile-managed and internally pinned buffers are used.  \n          The cuFileBufDeregister API is used to optimally clean up cuFile-related memory objects, but CUDA currently has no analog to cuFileBufDeregister. The cleaning up of objects associated with the buffers operated on in the cuFile context occurs at cuFileDriverClose. If explicit APIs are used, the incurred errors are reported immediately, but if the operations of these explicit APIs are performed implicitly, error reporting and handling are less clear. \n         CUfileError_t cuFileBufRegister(const void *devPtr_base, size_t size, int flags);\nCUfileError_t cuFileBufDeregister(const void *devPtr_base); \n \n          Refer to sample_005 for usage. \n         \n  \n  \n        \n        Operations that are enqueued with cuFile Stream APIs are FIFO ordered with respect to other work on the stream and must be completed before continuing with the next action in the stream.  \n CUfileError_t cuFileReadAsync(CUFileHandle_t fh, void *bufPtr_base, \n                  size_t *size_p, off_t *file_offset_p, off_t *bufPtr_offset_p,\n                  ssize_t *bytes_read_p, CUStream stream);\nCUfileError_t cuFileWriteAsync(CUFileHandle_t fh, void *bufPtr_base, \n                  size_t *size_p, off_t *file_offset_p, off_t *bufPtr_offse_pt,\n                  ssize_t *bytes_written_p, CUstream stream); \n \n          Refer to samples sample_031, sample_032, sample_033, and sample_034 for usage. \n         \n  \n  \n        \n        Batch APIs are submitted synchronously, but executed asynchronously with respect to host thread.  \n        \n          These operations can be submitted on different files, different locations in the same file, or a mix. Completion of IO can be checked asynchronously using a status API in the same host thread or in a different thread. The cuFileBatchIOGetStatus API takes an array of CUfileIOEvents_t and minimum number of elements to poll for. which describes the IO action, status, errors, and bytes transacted for each instance. The bytes transacted field is valid only when the status indicates a successful completion. \n          \n           Refer to samples sample_019, sample_020, sample_021, and sample_022 for usage. \n          \n \n  \n       \n       \n       This section provides information about the cuFile API functional specification.   See the GPUDirect Storage Overview Guide for a high-level analysis of the set of functions and their relation to each other. We anticipate adding additional return codes for some of these functions.  \n         All cuFile APIs are called from the host code. \n      \n \n  \n       This section provides information about the cuFileDriver API functional specification.   \n CUfileError_t cuFileDriverOpen(); \n  Opens the Driver session to support GDS IO operations. \n           Parameters\n  Returns\n This can happen when the character device (/dev/nvidia_fs[0-15]) is restricted to certain users by an administrator, for example, admin, where /dev is not exposed with read permissions in the container.   CU_FILE_DRIVER_VERSION_MISMATCH, when there is a mismatch between the cuFile library and its kernel driver.   Refer to the cufile.log file for more information.  \n           Description\n If the JSON configuration file does not exist, the API loads the default library settings. To modify this default config file, administrative privileges are needed. The administrator can modify it to grant cuFile access to the specified devices and mount paths and also tune IO parameters (in KB, 4K aligned) that are based on the type of workload. Refer to the default config file (/etc/cufile.json) for more information.  \n \n CUfileError_t cuFileDriverClose(); \n  Parameters\n  Returns\n  Description\n \n \n  \n         \n         The cuFileDrvProps_t structure can be queried with cuFileDriverGetProperties and selectively modified with cuFileDriverSetProperties. The structure is self-describing, and its fields are consistent with the major and minor API version parameters.  CUfileError_t cuFileDriverGetProperties(cuFileDrvProps_t *props); \n  Parameters\n  props\n  Returns\n  Description\n  This API is used to get current GDS properties and nvidia-fs driver properties and functionality, such as support for SCSI, NVMe, and NVMe-OF.  \n           This API is used to get the current nvidia-fs drivers-specific properties such as the following:  \n          Otherwise, the compatible mode is disabled.  Additional Information \n         \n          See the following for more information: \n           \n  \n \ncuFileDriverSetPollMode(bool poll, size_t poll_threshold_size) API  CUfileError_t cuFileDriverSetPollMode(bool poll,\n                                       size_t poll_threshold_size); \n  Parameters\n  poll\n  poll_threshold_size\n  Returns\n  Description\n  This API is used in conjunction with cuFileGetDriverProperties. This API is used to set whether the library should use polling and the maximum IO threshold size less than or equal to which it will poll.  \n           This API overrides the default value that may be set through the JSON configuration file using the config keys properties.poll_modeand properties.poll_max_size_kb for the current process.  \n         \n          See the following for more information: \n           \n  \n CUfileError_t cuFileDriverSetMaxDirectIOSize(size_t max_direct_io_size); \n This parameter is used by the nvidia-fs driver as the maximum IO chunk size in which IO is issued to the underlying filesystem. In compatible mode, this is the maximum IO chunk size that the library uses to issue POSIX read/writes.   Parameters\n  max_direct_io_size\n  Returns\n  Description\n  This API is used with cuFileGetDriverProperties and is used to set the maximum direct IO size used by the library to specify the nvidia-fs kernel driver the maximum chunk size in which the latter can issue IO to the underlying filesystem. In compatible mode, this is the maximum IO chunk size which the library uses for issuing POSIX read/writes. This parameter is dependent on the underlying GPU hardware and system memory.  \n           This API overrides the default value that might be set through the JSON configuration file by using the properties.max_direct_io_size_kb config key for the current process.  \n         \n          Refer to the following for more information: \n           \n  \n CUfileError_t cuFileDriverSetMaxCacheSize(size_t max_cache_size); \n  Parameters\n  max_cache_size\n  Returns\n  Description\n  This API is used with cuFileGetDriverProperties and is used to set the upper limit on the cache size per device for internal use by the library.  \n           See cuFileDriverGetProperties for more information.  \n          \n CUfileError_t cuFileDriverSetMaxPinnedMemSize(size_t max_pinned_mem_size); \n  Parameters\n  max_pinned_memory_size\n  Returns\n  Description\n  This API is used with cuFileGetDriverProperties and is used to set an upper limit on the maximum size of GPU memory that can be pinned and mapped and is dependent on the underlying GPU hardware and system memory. This API is related to cuFileBufRegister, which is used to register GPU device memory. SeecuFileDriverGetProperties for more information.  \n         \n \n  \n        \n        This section provides information about the cuFile IO API function specification.   The device pointer addresses referred to in these APIs pertain to the current context for the caller.  \n          Unlike the non-async version of cuMemcpy, the cuFileHandleRegister, cuFileHandleDeregister, cuFileRead, and cuFileWrite APIs do not have the semantic of being ordered with respect to other work in the null stream.  \n       \n \n CUfileError_t cuFileHandleRegister(CUFileHandle_t *fh, CUfileDescr_t *descr); \n \n             CUDA toolkit 12.2 (GDS version 1.7.x) supports non O_DIRECT open flags as well as O_DIRECT. Application is allowed to open a file in non O_DIRECT mode in compat mode and also with nvidia-fs.ko installed. In the latter case, an O_DIRECT path between GPU and Storage will be used if such a path exists. \n            Parameters\n Valid pointer to the OS-neutral cuFile handle structure supplied by the user but populated and maintained by the cuFile runtime.  Valid pointer to the OS-neutral file descriptor supplied by the user carrying details regarding the file to be opened such as fd for Linux-based files.   Returns\n Description\n  \n         \n          Refer to the following for more information: \n           \n  \n CUfileError_t cuFileHandleDeregister(CUFileHandle_t *fh); \nParameters\n The file handle obtained from cuFileHandleRegister.   Returns\n  None \n          \n           \n            This API only logs an ERROR level message in the cufile.log file for valid inputs. \n           Description\n\n This API should be invoked only after the application ensures there are no outstanding IO operations with the handle. If cuFileHandleDeregister is called while IO on the file is in progress might result in undefined behavior.  Closing a file handle without calling cuFileHandleDeregister does not release the resources that are held in the cuFile library. If this API is not called, the cuFile subsystem releases the resources lazily or when the application exits.   \n         \n          See the following for more information: \n           \n  \n ssize_t cuFileRead(CUfileHandle_tfh, void *bufPtr_base, size_t size, off_t file_offset, off_t bufPtr_offset); \n Parameters\n File descriptor for the file. Base address of buffer in device memory or host memory. For registered buffers, bufPtr_base must remain set to the base address used in the cuFileBufRegister call.  Size in bytes to read. Offset in the file to read from. Offset relative to the bufPtr_base pointer to read into. This parameter should be used only with registered buffers.   Returns\n  Description\n  This API reads the data from a specified file handle at a specified offset and size bytes into the GPU memory by using GDS functionality or into the host memory based on the type of memory pointer. The API works correctly for unaligned offsets and any data size, although the performance might not match the performance of aligned reads.This is a synchronous call and blocks until the IO is complete.  \n          \n           For the bufPtr_offset, if data will be read starting exactly from the bufPtr_base that is registered with cuFileBufRegister, bufPtr_offset should be set to 0. To read starting from an offset in the registered buffer range, the relative offset should be specified in the bufPtr_offset, and the bufPtr_base must remain set to the base address that was used in the cuFileBufRegister call. \n           \n         \n          See the following for more information: \n           \n  \n ssize_t cuFileWrite(CUfileHandle_t fh, const void *bufPtr_base, size_t size, off_t file_offset, off_t bufPtr_offset); \n Parameters\n File descriptor for the file Base address of buffer in device memory or host memory. For registered buffers, bufPtr_base must remain set to the base address used in the cuFileBufRegister call.  Size in bytes to which to write. Offset in the file to which to write. Offset relative to the bufPtr_base pointer from which to write. This parameter should be used only with registered buffers.   Returns\n  Description\n  This API writes the data from the GPU memory or the host memory to a file specified by the file handle at a specified offset and size bytes by using GDS functionality. The API works correctly for unaligned offset and data sizes, although the performance is not on-par with aligned writes.This is a synchronous call and will block until the IO is complete.  \n          \n           GDS functionality modified the standard file system metadata in SysMem. However, GDS functionality does not take any special responsibility for writing that metadata back to permanent storage. The data is not guaranteed to be present after a system crash unless the application uses an explicit fsync(2) call. If the file is opened with an O_SYNC flag, the metadata will be written to the disk before the call is complete. \n          \n  Refer to the note in cuFileRead for more information about bufPtr_offset:.  \n         \n          Refer to the following for more information: \n           \n \n \n  \n        \n        The device pointer addresses that are mentioned in the APIs in this section pertain to the current context for the caller. cuFile relies on users to complete their own allocation before using the cuFileBufRegister API and free after using the cuFileBufDeregister API.  \n \n CUfileError_t cuFileBufRegister(const void *bufPtr_base,\n                                size_t size, int flags); \n Parameters\n Address of device pointer. cuFileRead and cuFileWritemust use this bufPtr_base as the base address.  Size in bytes from the start of memory to map. Reserved for future use, must be 0.  Returns\n  Description\n  Based on the memory type, this API either registers the specified GPU address or host memory address and size for use with the cuFileRead and cuFileWrite operations. The user must call cuFileBufDeregister to release the pinned memory mappings for GPU memory if needed.  \n         \n          See the following for more information: \n           \n  \n CUfileError_t cuFileBufDeregister(const void *bufPtr_base); \n Parameters\n Address of device pointer to release the mappings that were provided to cuFileBufRegister  Returns\n  Description\n  This API deregisters memory mappings that were registered by cuFileBufRegister. Refer to cuFileBufRegister for more information.  \n         \n \n  \n        \n        This section provides information about the cuFile stream API functional specification.   The stream APIs are similar to Read and Write, but they take a stream parameter to support asynchronous operations and execute in the CUDA stream order.  \n       \n \n CUfileError_t cuFileStreamRegister(CUStream_t stream, unsigned flags); \n Defines the input behavior for stream I/O APIs.  Parameters\n CUDA stream in which to enqueue the operation. If NULL, make this operation in the default CUDA stream.  The following are valid values:    \n           Using the flag \u20180XF\u2019 will perform best as the workflow can be optimized during submission time. \n          \n  Description\n  This optional API registers the stream with the cuFile subsystem.  \n           This API will allocate resources to handle stream operations for cuFile. \n           The API will synchronize on the stream before allocating resources. \n           The stream pointer is expected to be a valid pointer. \n          \n           Returns\n \n \n CUfileError_t cuFileStreamDeregister(CUStream_t stream); \nParameters\n CUDA stream in which to enqueue the operation. If NULL, make this operation in the default CUDA stream.  Reserved for future use.  Description\n  This optional API deregisters the stream with the cuFile subsystem.  \n           This API will free allocated cuFile resources associated with the stream. \n           The API will synchronize on the stream before releasing resources. \n           The stream pointer is expected to be a valid pointer. \n           The stream will be automatically deregistered as part of cuFileDriverClose.  \n          \n           Returns\n \n \n CUfileError_t cuFileReadAsync(CUFileHandle_t fh,\n                        void *bufPtr_base, \n                        size_t *size_p,\n                        off_t *file_offset_p, \n                        off_t *bufPtr_offset_p,\n                        int *bytes_read_p,\n                        CUstream stream); \n The current context of the caller is assumed. Parameters\n The cuFile handle for the file. Pointer to size in bytes to read. If the exact size is not known at the time of I/O submission, then you must set it to the maximum possible I/O size for that stream I/O.  Pointer to offset in the file from which to read. Unless otherwise set using cuFileStreamRegister API, this value will not be evaluated until execution time.  Pointer to the offset relative to the bufPtr_base pointer from which to write. Unless otherwise set using cuFileStreamRegister API, this value will not be evaluated until execution time.  Pointer to the bytes read from the specified filehandle. This pointer should be a non NULL value and *bytes_read_p set to 0. After successful execution of the operation in the stream, the value *bytes_read_p will contain either:   Returns\n CUresult code can be obtained by using CU_FILE_CUDA_ERR(err).   Description\n This is an asynchronous call and enqueues the operation into the specified CUDA stream and will not block the host thread for IO completion. The operation can be waited upon using cuStreamSynchronize(stream).  The pointer to access that memory from the device can be obtained by using cuMemHostGetDevicePointer.   \n         \n          Refer to the following for more information: \n           \n  \n CUfileError_t cuFileWriteAsync(CUFileHandle_t fh,\n                        void *bufPtr_base, \n                        size_t *size_p,\n                        off_t file_offset_p, \n                        off_t bufPtr_offset_p,\n                        int *bytes_written_p,\n                        CUstream_t stream); \n Parameters\n The cuFile handle for the file. The base address of the buffer in the memory from which to write. The buffer can be allocated using either cudaMemory/cudaMallocHost/malloc/mmap. For registered buffers, bufPtr_base must remain set to the base address used in the cuFileBufRegister call.  Pointer to the size in bytes to write. If the exact size is not known at the time of I/O submission, then you must set it to the maximum possible I/O size for that stream I/O.  Pointer to the offset in the file from which to write. Unless otherwise set using cuFileStreamRegister API, this value will not be evaluated until execution time.  Pointer to the offset relative to the bufPtr_base pointer from which to write. Unless otherwise set using cuFileStreamRegister API, this value will not be evaluated until execution time.  Pointer to the bytes written to the specified filehandle.This pointer should be a non NULL value and *bytes_written_p set to 0. After successful execution of the operation in the stream, the value *bytes_written_p will contain either:  The CUDA stream to enqueue the operation.  Returns\n The CUresult code can be obtained by using CU_FILE_CUDA_ERR(err).   Description\n  \n         \n          See the following for more information: \n           \n \n \n  \n        \n        This section provides information about the cuFile Batch API functional specification. \n \n CUfileError_t\ncuFileBatchIOSetUp(CUfileBatchHandle_t *batch_idp, int max_nr); \nParameters\n \n               The number should be between 1 - \u201cproperties.io_batch_size\u201d \n               (Output) Will be used in subsequent batch IO calls.   Returns\n  Description\n  This interface should be the first call in the sequence of batch I/O operation. This takes the maximum number of batch entries the caller intends to use and returns a CUFileBatchHandle_twhich should be used by the caller for subsequent batch I/O calls.  \n         \n          See the following for more information: \n           \n  \n CUfileError_t cuFileBatchIOSubmit(CUfileBatchHandle_t batch_idp,\n                                 unsigned nr, \n                                 CUfileIOParams_t *iocbp,\n                                 unsigned int flags) \nParameters\n The address of the output parameter for the newly created batch ID, which was obtained from a cuFileBatchSetup call.  The pointer contains the CUfileIOParams_t array structures of the length nrarray.  Reserved for future use. Should be set to 0.  Returns\n  Description\n Based on the type of memory pointer, the data is transferred to/from the GPU memory by using GDS or the data is transferred to/from the CPU memory.  The bytes transacted field is valid only when the status indicates a completion.   \n         \n          See the following for more information: \n           \n  \n CUfileError_t cuFileBatchIOGetStatus(CUfileBatchHandle_t batch_idp, \n                                     unsigned min_nr,\n                                     unsigned *nr,\n                                     CUfileIOEvents_t *iocbp,\n                                     struct timespec* timeout)); \nParameters\n Obtained during setup. The minimum number of IO entries for which status is requested. The min_nr should be greater than or equal to zero and less than or equal to *nr.  This is a pointer to max requested IO entries to poll for completion and is used as an Input/Output parameter. As an input *nr must be set to pass the maximum number of IO requests to poll for. As an output, *nr returns the number of completed I/Os.   CUFileIOEvents_t array containing the status of completed I/Os in that batch.   This parameter is used to specify the amount of time to wait for in this API, even if the minimum number of requests have not completed. If the timeout hits, it is possible that the number of returned IOs can be less than min_nr.   Returns\n The success here refers to the completion of the API. Individual IO status and error can be obtained by examining the returned status and error in the array iocbp.   Description\n  \n         \n          See the following for more information: \n           \n  \n CUfileError_t cuFileBatchIOCancel(CUfileBatchHandle_t batch_idp) \nParameters\n The batch ID to cancel.  Returns\n  Description\n  \n         \n          Refer to the following for more information: \n           \n  \n void cuFileBatchIODestroy(CUfileBatchHandle_t batch_idp) \nParameters\n The batch handle to be destroyed.  Returns\n  void \n           Description\n  This is a batch API that destroys a batch context and the resources that are allocated with cuFileBatchIOSetup.  \n         \n          Refer to the following for more information: \n           \n \n  \n  The following sample program uses the cuFile APIs:\n        // To compile this sample code:\n//\n// nvcc gds_helloworld.cxx -o gds_helloworld -lcufile\n//\n// Set the environment variable TESTFILE\n// to specify the name of the file on a GDS enabled filesystem\n//\n// Ex:   TESTFILE=/mnt/gds/gds_test ./gds_helloworld\n//\n//\n#include <fcntl.h>\n#include <errno.h>\n#include <unistd.h>\n\n#include <cstdlib>\n#include <cstring>\n#include <iostream>\n#include <cuda_runtime.h>\n#include \"cufile.h\"\n\n//#include \"cufile_sample_utils.h\"\nusing namespace std;\n\nint main(void) {\n        int fd;\n        ssize_t ret;\n        void *devPtr_base;\n        off_t file_offset = 0x2000;\n        off_t devPtr_offset = 0x1000;\n        ssize_t IO_size = 1UL << 24;\n        size_t buff_size = IO_size + 0x1000;\n        CUfileError_t status;\n        // CUResult cuda_result;\n        int cuda_result;\n        CUfileDescr_t cf_descr;\n        CUfileHandle_t cf_handle;\n        char *testfn;\n        \n        testfn=getenv(\"TESTFILE\");\n        if (testfn==NULL) {\n            std::cerr << \"No testfile defined via TESTFILE.  Exiting.\" << std::endl;\n            return -1;\n        } \n       \n        cout << std::endl; \n        cout << \"Opening File \" << testfn << std::endl;\n\n        fd = open(testfn, O_CREAT|O_WRONLY|O_DIRECT, 0644);\n        if(fd < 0) {\n                std::cerr << \"file open \" << testfn << \"errno \" << errno << std::endl;\n                return -1;\n        }\n\n        // the above fd could also have been opened without O_DIRECT starting CUDA toolkit 12.2\n        // (gds 1.7.x version) as follows\n        // fd = open(testfn, O_CREAT|O_WRONLY, 0644);\n\n        cout << \"Opening cuFileDriver.\" << std::endl;\n        status = cuFileDriverOpen();\n        if (status.err != CU_FILE_SUCCESS) {\n                std::cerr << \" cuFile driver failed to open \" << std::endl;\n                close(fd);\n                return -1;\n        }\n\n        cout << \"Registering cuFile handle to \" << testfn << \".\" << std::endl;\n\n        memset((void *)&cf_descr, 0, sizeof(CUfileDescr_t));\n        cf_descr.handle.fd = fd;\n        cf_descr.type = CU_FILE_HANDLE_TYPE_OPAQUE_FD;\n        status = cuFileHandleRegister(&cf_handle, &cf_descr);\n        if (status.err != CU_FILE_SUCCESS) {\n                std::cerr << \"cuFileHandleRegister fd \" << fd << \" status \" << status.err << std::endl;\n                close(fd);\n                return -1;\n        }\n\n        cout << \"Allocating CUDA buffer of \" << buff_size << \" bytes.\" << std::endl;\n\n        cuda_result = cudaMalloc(&devPtr_base, buff_size);\n        if (cuda_result != CUDA_SUCCESS) {\n                std::cerr << \"buffer allocation failed \" << cuda_result << std::endl;\n                cuFileHandleDeregister(cf_handle);\n                close(fd);\n                return -1;\n        }\n\n        cout << \"Registering Buffer of \" << buff_size << \" bytes.\" << std::endl;\n        status = cuFileBufRegister(devPtr_base, buff_size, 0);\n        if (status.err != CU_FILE_SUCCESS) {\n                std::cerr << \"buffer registration failed \" << status.err << std::endl;\n                cuFileHandleDeregister(cf_handle);\n                close(fd);\n                cudaFree(devPtr_base);\n                return -1;\n        }\n\n        // fill a pattern\n        cout << \"Filling memory.\" << std::endl;\n\n        cudaMemset((void *) devPtr_base, 0xab, buff_size);\n        cuStreamSynchronize(0);\n\n        // perform write operation directly from GPU mem to file\n        cout << \"Writing buffer to file.\" << std::endl;\n        ret = cuFileWrite(cf_handle, devPtr_base, IO_size, file_offset, devPtr_offset);\n\n        if (ret < 0 || ret != IO_size) {\n                std::cerr << \"cuFileWrite failed \" << ret << std::endl;\n        }\n\n        // release the GPU memory pinning\n        cout << \"Releasing cuFile buffer.\" << std::endl;\n        status = cuFileBufDeregister(devPtr_base);\n        if (status.err != CU_FILE_SUCCESS) {\n                std::cerr << \"buffer deregister failed\" << std::endl;\n                cudaFree(devPtr_base);\n                cuFileHandleDeregister(cf_handle);\n                close(fd);\n                return -1;\n        }\n\n        cout << \"Freeing CUDA buffer.\" << std::endl;\n        cudaFree(devPtr_base);\n        // deregister the handle from cuFile\n        cout << \"Releasing file handle. \" << std::endl;\n        (void) cuFileHandleDeregister(cf_handle);\n        close(fd);\n\n        // release all cuFile resources\n        cout << \"Closing File Driver.\" << std::endl;\n        (void) cuFileDriverClose();\n\n        cout << std::endl; \n\n        return 0;\n} \n\n  \n       \n       \n       This section provides information about the known limitations of cuFile Batch APIs in this release of GDS.  The following table provides an overview of cuFile batch API support with respect to distributed file systems:      \n \n   This document is provided for information purposes only and shall not be regarded as a warranty of a certain functionality, condition, or quality of a product. NVIDIA Corporation (\u201cNVIDIA\u201d) makes no representations or warranties, expressed or implied, as to the accuracy or completeness of the information contained in this document and assumes no responsibility for any errors contained herein. NVIDIA shall have no liability for the consequences or use of such information or for any infringement of patents or other rights of third parties that may result from its use. This document is not a commitment to develop, release, or deliver any Material (defined below), code, or functionality.\n   NVIDIA reserves the right to make corrections, modifications, enhancements, improvements, and any other changes to this document, at any time without notice.\n   Customer should obtain the latest relevant information before placing orders and should verify that such information is current and complete.\n   NVIDIA products are sold subject to the NVIDIA standard terms and conditions of sale supplied at the time of order acknowledgement, unless otherwise agreed in an individual sales agreement signed by authorized representatives of NVIDIA and customer (\u201cTerms of Sale\u201d). NVIDIA hereby expressly objects to applying any customer general terms and conditions with regards to the purchase of the NVIDIA product referenced in this document. No contractual obligations are formed either directly or indirectly by this document.\n   NVIDIA products are not designed, authorized, or warranted to be suitable for use in medical, military, aircraft, space, or life support equipment, nor in applications where failure or malfunction of the NVIDIA product can reasonably be expected to result in personal injury, death, or property or environmental damage. NVIDIA accepts no liability for inclusion and/or use of NVIDIA products in such equipment or applications and therefore such inclusion and/or use is at customer\u2019s own risk.\n   NVIDIA makes no representation or warranty that products based on this document will be suitable for any specified use. Testing of all parameters of each product is not necessarily performed by NVIDIA. It is customer\u2019s sole responsibility to evaluate and determine the applicability of any information contained in this document, ensure the product is suitable and fit for the application planned by customer, and perform the necessary testing for the application in order to avoid a default of the application or the product. Weaknesses in customer\u2019s product designs may affect the quality and reliability of the NVIDIA product and may result in additional or different conditions and/or requirements beyond those contained in this document. NVIDIA accepts no liability related to any default, damage, costs, or problem which may be based on or attributable to: (i) the use of the NVIDIA product in any manner that is contrary to this document or (ii) customer product designs.\n   No license, either expressed or implied, is granted under any NVIDIA patent right, copyright, or other NVIDIA intellectual property right under this document. Information published by NVIDIA regarding third-party products or services does not constitute a license from NVIDIA to use such products or services or a warranty or endorsement thereof. Use of such information may require a license from a third party under the patents or other intellectual property rights of the third party, or a license from NVIDIA under the patents or other intellectual property rights of NVIDIA.\n   Reproduction of information in this document is permissible only if approved in advance by NVIDIA in writing, reproduced without alteration and in full compliance with all applicable export laws and regulations, and accompanied by all associated conditions, limitations, and notices.\n   THIS DOCUMENT AND ALL NVIDIA DESIGN SPECIFICATIONS, REFERENCE BOARDS, FILES, DRAWINGS, DIAGNOSTICS, LISTS, AND OTHER DOCUMENTS (TOGETHER AND SEPARATELY, \u201cMATERIALS\u201d) ARE BEING PROVIDED \u201cAS IS.\u201d NVIDIA MAKES NO WARRANTIES, EXPRESSED, IMPLIED, STATUTORY, OR OTHERWISE WITH RESPECT TO THE MATERIALS, AND EXPRESSLY DISCLAIMS ALL IMPLIED WARRANTIES OF NONINFRINGEMENT, MERCHANTABILITY, AND FITNESS FOR A PARTICULAR PURPOSE. TO THE EXTENT NOT PROHIBITED BY LAW, IN NO EVENT WILL NVIDIA BE LIABLE FOR ANY DAMAGES, INCLUDING WITHOUT LIMITATION ANY DIRECT, INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE, OR CONSEQUENTIAL DAMAGES, HOWEVER CAUSED AND REGARDLESS OF THE THEORY OF LIABILITY, ARISING OUT OF ANY USE OF THIS DOCUMENT, EVEN IF NVIDIA HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. Notwithstanding any damages that customer might incur for any reason whatsoever, NVIDIA\u2019s aggregate and cumulative liability towards customer for the products described herein shall be limited in accordance with the Terms of Sale for the product.\n \n \n  OpenCL is a trademark of Apple Inc. used under license to the Khronos Group Inc. \n         \n \n  NVIDIA, the NVIDIA logo, DGX, DGX-1, DGX-2, DGX-A100, Tesla, and Quadro are trademarks and/or registered trademarks of NVIDIA Corporation in the United States and other countries. Other company and product names may be trademarks of the respective companies with which they are associated.  \n         \n Privacy Policy | Manage My Privacy | Do Not Sell or Share My Data | Terms of Service | Accessibility | Corporate Policies | Product Security | Contact Copyright \u00a9 2024 NVIDIA Corporation", "https://nvidia.github.io/cccl/thrust/": "Thrust is the C++ parallel algorithms library which inspired the introduction\nof parallel algorithms to the C++ Standard Library.\nThrust\u2019s high-level interface greatly enhances programmer productivity\nwhile enabling performance portability between GPUs and multicore CPUs.\nIt builds on top of established parallel programming frameworks (such as CUDA,\nTBB, and OpenMP).\nIt also provides a number of general-purpose facilities similar to those found\nin the C++ Standard Library. Thrust is an open source project; it is available on\nGitHub and included in the NVIDIA HPC SDK and CUDA Toolkit.\nIf you have one of those SDKs installed, no additional installation or compiler\nflags are needed to use Thrust. Thrust is best learned through examples. The following example generates random numbers serially and then transfers them\nto a parallel device where they are sorted. See it on Godbolt This example demonstrates computing the sum of some random numbers in parallel: See it on Godbolt This example show how to perform such a reduction asynchronously: See it on Godbolt Thrust is a header-only library; there is no need to build or install the project unless you want to run the Thrust unit tests.\nThe CUDA Toolkit provides a recent release of the Thrust source code in include/thrust. This will be suitable for most users.\nUsers that wish to contribute to Thrust or try out newer features should recursively clone the Thrust Github repository: For CMake-based projects, we provide a CMake package for use with find_package. See the CMake README for more information.\nThrust can also be added via add_subdirectory or tools like the CMake Package Manager. For non-CMake projects, compile with: The Thrust include path (-I<thrust repo root>) The libcu++ include path (-I<thrust repo root>/dependencies/libcudacxx/) The CUB include path, if using the CUDA device system (-I<thrust repo root>/dependencies/cub/) By default, the CPP host system and CUDA device system are used.\nThese can be changed using compiler definitions: -DTHRUST_HOST_SYSTEM=THRUST_HOST_SYSTEM_XXX,\nwhere XXX is CPP (serial, default), OMP (OpenMP), or TBB (Intel TBB) -DTHRUST_DEVICE_SYSTEM=THRUST_DEVICE_SYSTEM_XXX, where XXX is\nCPP, OMP, TBB, or CUDA (default). Thrust uses the CMake build system to build unit tests, examples, and header tests.\nTo build Thrust as a developer, it is recommended that you use our containerized development system: That does the equivalent of the following, but in a clean containerized environment which has all dependencies installed: By default, a serial CPP host system, CUDA accelerated device system, and C++14 standard are used.\nThis can be changed in CMake and via flags to ci/local/build.bash More information on configuring your Thrust build and creating a pull request can be found in the contributing section. Thrust is an open source project developed on GitHub.\nThrust is distributed under the Apache License v2.0 with LLVM Exceptions.\nSome parts are distributed under the Apache License v2.0 and the Boost License v1.0. \u00a9 Copyright 2024, NVIDIA.\n      Last updated on Jul 25, 2024.\n      ", "https://docs.nvidia.com/datacenter/tesla/mig-user-guide/index.html": "User guide for Multi-Instance GPU on the NVIDIA\u00ae GPUs. This edition of the user guide describes the Multi-Instance GPU feature first introduced\n                        with the NVIDIA\u00ae Ampere architecture.\n                       \n                        The new Multi-Instance GPU (MIG) feature allows GPUs (starting with NVIDIA Ampere \n                        architecture) to be securely partitioned into up to seven \n                        separate GPU Instances for CUDA applications, providing multiple users with separate \n                        GPU resources for optimal GPU utilization. This feature is particularly beneficial for \n                        workloads that do not fully saturate the GPU's compute capacity and therefore users may want to \n                        run different workloads in parallel to maximize utilization. \n                        \n                      \n                        For Cloud Service Providers (CSPs), who have multi-tenant use cases, MIG ensures one client \n                        cannot impact the work or scheduling of other clients, in addition to providing enhanced isolation for customers. \n                        \n                      \n                        With MIG, each instance's processors have separate and isolated paths through the entire\n                        memory system - the on-chip crossbar ports, L2 cache banks, memory controllers, and DRAM\n                        address busses are all assigned uniquely to an individual instance. This ensures that an\n                        individual user's workload can run with predictable throughput and latency, with the same L2\n                        cache allocation and DRAM bandwidth, even if other tasks are thrashing their own caches or\n                        saturating their DRAM interfaces. MIG can partition available GPU compute resources (including \n                        streaming multiprocessors or SMs, and GPU engines such as copy engines or decoders), to provide \n                        a defined quality of service (QoS) with fault isolation for different clients such as VMs, \n                        containers or processes. MIG enables multiple GPU Instances to run in parallel on a single, physical \n                        NVIDIA Ampere GPU.\n                        \n                      \n                        With MIG, users will be able to see and schedule jobs on their new virtual GPU Instances as \n                        if they were physical GPUs. MIG works with Linux operating systems, supports containers using Docker Engine, \n                        with support for Kubernetes and virtual machines using hypervisors such as Red Hat Virtualization and \n                        VMware vSphere.\n                        \n                      Bare-metal, including containers GPU pass-through virtualization to Linux guests on top of supported hypervisors vGPU on top of supported hypervisors MIG allows multiple vGPUs (and thereby VMs) to run in parallel on a single GPU, while preserving the isolation guarantees\n                        \n                        that vGPU provides. For more information on GPU partitioning using vGPU and MIG, refer to the \n                        technical brief.\n                        \n                      \n                        The purpose of this document is to introduce the concepts behind MIG, deployment considerations and \n                        provide examples of MIG management to demonstrate how users can run CUDA applications on MIG supported GPUs. \n                        \n                      MIG is supported on GPUs starting with the NVIDIA Ampere generation (i.e. GPUs with\n                        compute capability >= 8.0). The following table provides a list of supported GPUs: \n                      \n                        Additionally, MIG is supported on systems that include the supported products above such as \n                        DGX, DGX Station and HGX.\n                        \n                      Bare-metal, including containers and Kubernetes GPU pass-through virtualization to Linux guests on top of supported hypervisors vGPU on top of supported hypervisors \n                                 Under Linux guests on supported hypervisors, when MIG-supported GPUs are \n                                 in GPU pass-through, the same \n                                 workflows, tools \n                                 and profiles available \n                                 on bare-metal can be used.\n                                 \n                               \n                                 MIG allows multiple vGPUs (and thereby VMs) to run in parallel on a single \n                                 MIG-supported GPU, while preserving the isolation guarantees that vGPU provides.\n                                 To configure a GPU for use with vGPU VMs, refer to the \n                                 chapter in the vGPU Software User\n                                 Guide.\n                                 Refer also to the \n                                 technical brief for more information on GPU partitioning with vGPU.\n                                 \n                                \n                           This section introduces some terminology used to describe the concepts behind MIG.\n                           \n                         A streaming multiprocessor (SM) executes compute instructions on the GPU. Fault isolation Individually scheduled Distinct address space A GPU engine is what executes work on the GPU. The most commonly used engine is the \n                              Compute/Graphics engine that executes the compute instructions. Other engines include the \n                              copy engine (CE) that is responsible for performing DMAs, NVDEC for video decoding, NVENC \n                              for encoding, etc. Each engine can be scheduled independently and execute work for different \n                              GPU contexts.\n                            A GPU memory slice is the smallest fraction of the GPU's memory, including the \n                              corresponding memory controllers and cache. A GPU memory slice is roughly one eighth of the \n                              total GPU memory resources, including both capacity and bandwidth.\n                            A GPU SM slice is the smallest fraction of the SMs on the GPU. A GPU SM slice is \n                              roughly one seventh of the total number of SMs available in the GPU when configured in MIG mode.\n                            A GPU slice is the smallest fraction of the GPU that combines a single GPU memory slice \n                              and a single GPU SM slice.\n                            A GPU Instance (GI) is a combination of GPU slices and GPU engines (DMAs, NVDECs, etc.). \n                              Anything within a GPU instance always shares all the GPU memory slices and other GPU engines, \n                              but it's SM slices can be further subdivided into compute instances (CI). A GPU instance provides \n                              memory QoS. Each GPU slice includes dedicated GPU memory resources which limit both the available \n                              capacity and bandwidth, and provide memory QoS. Each GPU memory slice gets 1/8 of the total GPU \n                              memory resources and each GPU SM slice gets 1/7 of the total number of SMs. \n                            A GPU instance can be subdivided into multiple compute instances. A Compute Instance (CI) contains \n                              a subset of the parent GPU instance's SM slices and other GPU engines (DMAs, NVDECs, etc.). \n                              The CIs share memory and engines.\n                            \n                           Using the concepts introduced above, this section provides an overview of how the user can \n                           create various partitions on the GPU. For illustration purposes, the document will use the \n                           A100-40GB as an example, but the process is similar for other GPUs that support MIG. \n                           \n                         \n                              Partitioning of the GPU happens using memory slices, so the A100-40GB GPU can be thought \n                              of having 8x5GB memory slices and 7 SM slices as shown in the diagram below. \n                              \n                            \n                              As explained above, then to create a GPU Instance (GI) requires combining some number of \n                              memory slices with some number of compute slices. In the diagram below, a 5GB memory \n                              slice is combined with 1 compute slice to create a 1g.5gb GI profile: \n                              \n                            \n                              Similarly, 4x5GB memory slices can be combined with 4x1 compute slices to create the \n                              4g.5gb GI profile:\n                              \n                            \n                              The compute slices of a GPU Instance can be further subdivided into multiple \n                              Compute Instances (CI), with the CIs sharing the engines and memory of the parent GI, \n                              but each CI has dedicated SM resources.\n                              \n                            \n                              Using the same 4g.20gb example above, a CI may be created to consume only the first \n                              compute slice as shown below:\n                              \n                            \n                              In this case, 4 different CIs can be created by choosing any of the compute slices. Two compute \n                              slices can also be combined together to create a 2c.4g.20gb profile:\n                              \n                            \n                              In this example, 3 compute slices can also be combined to create a 3c.4g.20gb \n                              profile or all 4 can be combined to create a 4c.4g.20gb profile. When all 4 \n                              compute slices are combined, the profile is simply referred to as the 4g.20gb profile. \n                              \n                            \n                              Refer to the sections on the  canonical naming scheme  and \n                              the  CUDA device terminology.\n                              \n                            \n                              The number of slices that a GI can be created with is not arbitrary. The NVIDIA driver \n                              APIs provide a number of \u201cGPU Instance Profiles\u201d and users can create GIs by specifying \n                              one of these profiles.\n                              \n                            \n                              On a given GPU, multiple GIs can be created from a mix and match of these profiles, so long \n                              as enough slices are available to satisfy the request. \n                              \n                             \n                                 The table below shows the profile names on the A100-SXM4-40GB product. For A100-SXM4-80GB, the \n                                 profile names will change according to the memory proportion - for example, 1g.10gb, \n                                 2g.20gb, 3g.40gb, 4g.40gb, 7g.80gb \n                                 respectively.\n                                 \n                               \n                                 For a list of all supported combinations of profiles on MIG-enabled GPUs, refer to the section on \n                                 supported profiles.\n                                 \n                               The diagram below shows a pictorial representation of how to build all valid\n                              combinations of GPU instances. \n                            In this diagram, a valid combination can be built by starting with an instance\n                              profile on the left and combining it with other instance profiles as you move to the\n                              right, such that no two profiles overlap vertically.  For a list of all supported\n                              combinations and placements of profiles on A100 and A30, refer to the section on\n                              supported profiles. \n                            Note that prior to NVIDIA driver release R510, the combination of a (4 memory, 4\n                              compute) and a (4 memory, 3 compute) profile was not supported. This restriction no\n                              longer applies on newer drivers.\n                            \n                              Note that the diagram represents the physical layout of where the GPU Instances will exist once they \n                              are instantiated on the GPU. As GPU Instances are created and destroyed at different locations, \n                              fragmentation can occur, and the physical position of one GPU Instance will play a role in which other \n                              GPU Instances can be instantiated next to it.\n                              \n                            \n                           MIG has been designed to be largely transparent to CUDA applications - so that the \n                           CUDA programming model remains unchanged to minimize programming effort. CUDA already \n                           exposes multiple technologies for running work in parallel on the GPU and it is worthwhile \n                           showcasing how these technologies compare to MIG. Note that streams and MPS are part of the \n                           CUDA programming model and thus work when used with GPU Instances.\n                           \n                         \n                           CUDA Streams are a CUDA Programming model feature where, in a CUDA application, different \n                           work can be submitted to independent queues and be processed independently by the GPU. \n                           CUDA streams can only be used within a single process and don't offer much isolation - the \n                           address space is shared, the SMs are shared, the GPU memory bandwidth, caches and capacity \n                           are shared. And lastly any errors affect all the streams and the whole process.\n                           \n                         \n                           MPS is the CUDA Multi-Process service. It allows co-operative multi process applications to share \n                           compute resources on the GPU. It's commonly used by MPI jobs that cooperate, but it has also been \n                           used for sharing the GPU resources among unrelated applications, while accepting the challenges that \n                           such a solution brings. MPS currently does not offer error isolation between clients and while \n                           streaming multiprocessors used by each MPS client can be optionally limited to a percentage of all SMs, \n                           the scheduling hardware is still shared. Memory bandwidth, caches and capacity are all shared \n                           between MPS clients. \n                           \n                         \n                           Lastly, MIG is the new form of concurrency offered by NVIDIA GPUs while addressing some of the \n                           limitations with the other CUDA technologies for running parallel work. \n                           \n                          H100 GPUs are supported starting with CUDA 12/R525 drivers.  A100 and A30 GPUs are supported starting with CUDA 11/R450 drivers.  The following system considerations are relevant for when the GPU is in MIG mode.  MIG is supported only on Linux operating system distributions supported by CUDA. It is also recommended to use \n                                 the latest NVIDIA Datacenter Linux. Refer to the quick start guide.\n                               Also note the device nodes and nvidia-capabilities for exposing the MIG devices. The /proc mechanism \n                                    for system-level interfaces is deprecated as of 450.51.06 and it is recommended to use the /dev based system-level interface \n                                    for controlling access mechanisms of MIG devices through cgroups. This functionality is available starting with 450.80.02+\n                                    drivers.\n                                    \n                                  Bare-metal, including containers GPU pass-through virtualization to Linux guests on top of supported hypervisors vGPU on top of supported hypervisors  MIG allows multiple vGPUs (and thereby VMs) to run in parallel on a single A100, while preserving the isolation guarantees\n                                 \n                                 that vGPU provides. For more information on GPU partitioning using vGPU and MIG, refer to the \n                                 technical brief.\n                                 \n                               Setting MIG mode on the A100/A30 requires a GPU reset (and thus super-user privileges). \n                                 Once the GPU is in MIG mode, instance management is then dynamic. Note \n                                 that the setting is on a per-GPU basis.\n                               On NVIDIA Ampere GPUs, similar to ECC mode, MIG mode setting is persistent across reboots until the user toggles the setting\n                                 explicitly\n                               All daemons holding handles on driver modules need to be stopped before MIG enablement.  This is true for systems such as DGX which may be running system health monitoring services \n                                 such as nvsm \n                                 or GPU health monitoring or telemetry services such as \n                                 DCGM.\n                               Toggling MIG mode requires the CAP_SYS_ADMIN capability. Other MIG management, such as creating and destroying instances, \n                                 requires superuser by default, but can be delegated to non-privileged users by adjusting permissions to MIG capabilities \n                                 in /proc/.\n                                 \n                                Users should note the following considerations when the A100 is in MIG mode: No graphics APIs are supported (e.g. OpenGL, Vulkan etc.) No GPU to GPU P2P (either PCIe or NVLink) is supported CUDA applications treat a Compute Instance and its parent GPU Instance as a single CUDA device. \n                                 See this section on device enumeration by CUDA\n                               CUDA IPC across GPU instances is not supported. CUDA IPC across Compute instances is supported CUDA debugging (e.g. using cuda-gdb) and memory/race checking \n                                 (e.g. using cuda-memcheck or compute-sanitizer) is supported\n                               CUDA MPS is supported on top of MIG. The only limitation is that the maximum number of clients (48) is \n                                 lowered proportionally to the Compute Instance size\n                                 \n                               GPUDirect RDMA is supported when used from GPU Instances\n                                 \n                               \n                        By default, a MIG device consists of a single \u201cGPU Instance\u201d and a single \u201cCompute Instance\u201d. \n                        The table below highlights a naming convention to refer to a MIG device by its GPU Instance's \n                        compute slice count and its total memory in GB (rather than just its memory slice count).\n                        \n                      \n                        When only a single CI is created (that consumes the entire compute capacity of the GI), \n                        then the CI sizing is implied in the device name.\n                        \n                       \n                           The description below shows the profile names on the A100-SXM4-40GB product. For A100-SXM4-80GB, the \n                           profile names will change according to the memory proportion - for example, 1g.10gb, \n                           2g.20gb, 3g.40gb, 4g.40gb, 7g.80gb \n                           respectively.\n                           \n                         \n                        Each GI can be further sub-divided into multiple CIs as required by users depending on their workloads. The table \n                        below highlights what the name of a MIG device would look like in this case. The example shown is for \n                        subdividing a 3g.20gb device into a set of sub-devices with different Compute Instance slice counts.\n                        \n                      \n                           GPU Instances (GIs) and Compute Instances (CIs) are enumerated in the new /proc filesystem layout for MIG\n                           \n                         \n                           The corresponding device nodes (in mig-minors) are created under /dev/nvidia-caps.\n                           Refer to the chapter on  device nodes and capabilities  for more information.\n                           \n                         \n                           MIG supports running CUDA applications by specifying the CUDA device on which the application should be run. \n                           With CUDA 11/R450 and CUDA 12/R525, only enumeration of a single MIG instance is supported. In other words, \n                           regardless of how many MIG devices are created (or made available to a container), a single CUDA process \n                           can only enumerate a single MIG device. \n                           \n                         CUDA can only enumerate a single compute instance CUDA will not enumerate non-MIG GPU if any compute instance is enumerated on any other GPU \n                           Note that these constraints may be relaxed in future NVIDIA driver releases for MIG.\n                           \n                         \n                              With the R470 NVIDIA datacenter drivers (470.42.01+), the example below shows \n                              how MIG devices are assigned GPU UUIDs in an 8-GPU system with each GPU configured differently.\n                              \n                             \n                        This section provides an overview of the supported profiles and possible placements of the MIG profiles on \n                        supported GPUs.\n                        \n                      \n                           The following diagram shows the profiles supported on the NVIDIA A30:\n                           \n                          \n                           The table below shows the supported profiles on the A30-24GB product.\n                           \n                         The 1g.6gb+me profile is only available starting with R470 drivers.\n                            The 2g.12gb+me profile is only available starting with R525 drivers.\n                            \n                           The following diagram shows the profiles supported on the NVIDIA A100:\n                           \n                          \n                           The table below shows the supported profiles on the A100-SXM4-40GB product. For A100-SXM4-80GB, the \n                           profile names will change according to the memory proportion - for example, 1g.10gb, \n                           1g.10gb+me, 1g.20gb, 2g.20gb, 3g.40gb, \n                           4g.40gb, 7g.80gb respectively.\n                           \n                         The 1g.5gb+me profile is only available starting with R470 drivers.\n                            The 1g.10gb profile is only available starting with R525 drivers.\n                            \n                           The following diagram shows the profiles supported on the NVIDIA H100:\n                           \n                          \n                           The table below shows the supported profiles on the H100 80GB product (PCIe and SXM5). \n                           \n                         The following diagram shows the profiles supported on the NVIDIA H200:   The table below shows the supported profiles on the H200 141GB product.   The following prerequisites and minimum software versions are recommended when using supported GPUs in MIG mode.  MIG is supported only on GPUs and systems listed here It is recommended to install the latest NVIDIA datacenter driver. The minimum versions are provided below: Linux operating system distributions supported by \n                                 \n                                    CUDA If running containers or using Kubernetes, then: \n                           MIG can be managed programmatically using NVIDIA Management Library (NVML) APIs or its \n                           command-line-interface, nvidia-smi. Note that for brevity, some of the nvidia-smi \n                           output in the following examples may be cropped to showcase the relevant sections of interest. \n                           \n                         \n                           For more information on the MIG commands, see the nvidia-smi man page or nvidia-smi mig --help. \n                           For information on the MIG management APIs, see the NVML header (nvml.h) included in the CUDA Toolkit packages \n                           (cuda-nvml-dev-*; installed under /usr/local/cuda/include/nvml.h)\n                           For automated tooling support with configuring MIG, refer to the \n                           NVIDIA MIG Partition Editor (or mig-parted) \n                           tools. \n                           \n                         \n                           By default, MIG mode is not enabled on the GPU. For example, running nvidia-smi shows that MIG mode is disabled:\n                           \n                         \n                           MIG mode can be enabled on a per-GPU basis with the following command: \n                           nvidia-smi -i <GPU IDs> -mig 1. The GPUs can be selected using comma separated \n                           GPU indexes, PCI Bus Ids or UUIDs. If no GPU ID is specified, then MIG mode is applied to all the GPUs on the system.\n                           \n                         \n                           When MIG is enabled on the GPU, depending on the GPU product, the driver will attempt to reset the GPU so that MIG mode can\n                           take effect. \n                           \n                         \n                              Starting with the Hopper generation of GPUs, enabling MIG mode no longer requires a GPU reset to take \n                              effect (and thus the driver does not attempt to reset the GPU in the background).\n                              \n                            \n                              Note that MIG mode (Disabled or Enabled states) is only \n                              persistent as long as the driver is resident in the system (i.e. the kernel modules are loaded). MIG mode is \n                              no longer persistent across system reboots (there is no longer a status bit stored in the GPU InfoROM).  \n                              \n                            \n                              Thus, an unload and reload of the driver kernel modules will disable MIG mode.\n                              \n                            \n                              On NVIDIA Ampere GPUs, when MIG mode is enabled, the driver will attempt to reset the \n                              GPU so that MIG mode can take effect. \n                              \n                            \n                              Note that MIG mode (Disabled or Enabled states) \n                              is persistent across system reboots (there is a status bit stored in the GPU InfoROM). \n                              Thus MIG mode has to be explicitly disabled to return the GPU to its default state.\n                              \n                            \n                                 If you are using MIG inside a VM with NVIDIA Ampere GPUs (A100 or A30) in passthrough, then you may need to reboot the VM\n                                 to allow the GPU to be in MIG mode as in some cases, GPU reset is not \n                                 allowed via the hypervisor for security reasons. This can be seen in the following example:\n                                 \n                               \n                              In some cases, if you have agents on the system (e.g. monitoring agents) that use the GPU, then you may not be able to initiate\n                              a GPU reset. For example, on DGX systems, \n                              you may encounter the following message:\n                              \n                            \n                              In this specific DGX example, you would have to stop the nvsm and dcgm services, enable MIG mode on the desired GPU and then restore the monitoring services:\n                              \n                            \n                              The examples shown in the document use super-user privileges. As described in the  Device Nodes  \n                              section, granting read access to mig/config capabilities allows non-root users to manage instances once the GPU has been configured into MIG mode. \n                              The default file permissions on the mig/config file is shown below. \n                              \n                            \n                           The NVIDIA driver provides a number of profiles that users can opt-in for when configuring the MIG feature in A100. \n                           The profiles are the sizes and capabilities of the GPU instances that can be created by the user. \n                           The driver also provides information about the placements, which indicate the type and number of instances that can be created.\n                           \n                           \n                         \n                           List the possible placements available using the following command. The syntax of the placement is \n                           {<index>}:<GPU Slice Count> and shows the placement of the instances on the GPU.\n                           The placement index shown indicates how the profiles are mapped on the GPU as shown in the \n                           supported profiles tables.\n                           \n                         \n                           The command shows that the user can create two instances of type 3g.20gb (profile ID 9) or \n                           seven instances of 1g.5gb (profile ID 19). \n                           \n                         \n                           Once the GPU instances are created, one needs to create the corresponding Compute Instances (CI). By using the \n                           -C option, nvidia-smi creates these instances. \n                           \n                         Without creating GPU instances (and corresponding compute instances), CUDA workloads cannot be run on the GPU. In \n                              other words, simply enabling MIG mode on the GPU is not sufficient. Also note that, the created MIG devices are not \n                              persistent across system reboots. Thus, the user or system administrator needs to recreate the desired MIG configurations\n                              \n                              if the GPU or system is reset. For automated tooling support for this purpose, refer to the \n                              NVIDIA MIG Partition Editor (or mig-parted) \n                              tool, including creating a \n                              systemd service that could recreate the MIG geometry at system startup. \n                              \n                            \n                           The following example shows how the user can create GPU instances (and corresponding compute instances). In this example,\n                           the user can create \n                           two GPU instances (of type 3g.20gb), with each GPU instance having half of the available compute and memory capacity. In this \n                           example, we purposefully use profile ID and short profile name to showcase how either option can be used:\n                           \n                         \n                           Now list the available GPU instances:\n                           \n                         \n                           Now verify that the GIs and corresponding CIs are created:\n                           \n                         As described in the section on \n                                 Partitioning, the NVIDIA driver APIs provide a number of available GPU Instance profiles that can be chosen by the user.\n                              \n                            If a mixed geometry of the profiles is specified by the user, then the NVIDIA driver chooses the placement of the various\n                              profiles. This can be seen in the following \n                              examples.\n                              \n                            Example 1: Creation of a 4-2-1 geometry. After the instances are created, the placement of the profiles can be observed:\n                              \n                            Example 2: Creation of a 3-2-1-1 geometry. \n                              \n                            Due to a known issue with the APIs, the profile ID 9 or 3g.20gb must be specified first in order. \n                                 Not doing so, will result in the following error. \n                                 \n                               \n                              Specify the correct order for the 3g.20gb profile. The remaining combinations of the profiles do not have this requirement. \n                              \n                            Example 3: Creation of a 2-1-1-1-1-1 geometry:\n                              \n                            \n                              The following example shows how two CUDA applications can be run in parallel on two different GPU instances. In this example,\n                              \n                              the BlackScholes CUDA sample is run simultaneously on the two GIs created on the A100.\n                              \n                            \n                              Now verify the two CUDA applications are running on two separate GPU instances:\n                              \n                            NVML (and nvidia-smi) does not support attribution of utilization metrics to MIG devices. From the previous example, \n                                 the utilization is displayed as N/A when running CUDA programs:\n                                 \n                               \n                                 For monitoring MIG devices on MIG capable GPUs such as the A100, including attribution of GPU metrics \n                                 (including utilization and other profiling metrics), it is recommended to use NVIDIA DCGM v2.0.13 or later. \n                                 See the Profiling Metrics \n                                 section in the DCGM User Guide for more details on getting started.\n                                 \n                               \n                              As explained earlier in this document, a further level of concurrency can be achieved by using Compute Instances (CIs). \n                              The following example shows how 3 CUDA processes (BlackScholes CUDA sample) can be run on the same GI.\n                              \n                            \n                              First, list the available CI profiles available using our prior configuration of creating 2 GIs on the A100.\n                              \n                            \n                              Create 3 CIs, each of type 1c compute capacity (profile ID 0) on the first GI.\n                              \n                            \n                              Using nvidia-smi, the following CIs are now created on GI 1. \n                              \n                            \n                              And the GIs and CIs created on the A100 are now enumerated by the driver:\n                              \n                            \n                              Now, three BlackScholes applications can be created and run in parallel:\n                              \n                            \n                              And seen using nvidia-smi as running processes on the three CIs:\n                              \n                            \n                           Once the GPU is in MIG mode, GIs and CIs can be configured dynamically. \n                           The following example shows how the CIs and GIs created in the previous examples can be destroyed.\n                           \n                         \n                              If the intention is to destroy all the CIs and GIs, then this can be accomplished with \n                              the following commands:\n                              \n                            \n                           In this example, we delete the specific CIs created under GI 1.\n                           \n                         \n                           It can be verified that the CI devices have now been torn down on the GPU:\n                           \n                         \n                           Now the GIs have to be deleted: \n                           \n                         \n                           For monitoring MIG devices on including attribution of GPU metrics \n                           (including utilization and other profiling metrics), it is recommended to use NVIDIA DCGM v3 or later. \n                           See the Profiling Metrics \n                           section in the DCGM User Guide for more details on getting started.\n                           \n                         On Ampere GPUs (A100 or A30), NVML (and nvidia-smi) does not support attribution of utilization metrics to MIG devices. From the previous example, \n                              the utilization is displayed as N/A when running CUDA programs:\n                              \n                            \n                           As described in the section on CUDA concurrency mechanisms, \n                           CUDA Multi-Process \n                              Service (MPS) enables co-operative multi-process CUDA applications to be processed \n                           concurrently on the GPU. MPS and MIG can work together, potentially achieving even higher levels of utilization \n                           for certain workloads.\n                           \n                         \n                           Refer to the MPS documentation to understand the architecture and provisioning sequence for MPS. \n                           \n                         \n                           In the following sections, we will walk through an example of running MPS on MIG devices.\n                           \n                         \n                                       Configure the desired MIG geometry on the GPU.\n                                       \n                                     \n                                       Setup the CUDA_MPS_PIPE_DIRECTORY variable to point to unique directories \n                                       so that the multiple MPS servers and clients can communicate with each other using named pipes and \n                                       Unix domain sockets.\n                                       \n                                     \n                                       Launch the application by specifying the MIG device using CUDA_VISIBLE_DEVICES.\n                                       \n                                     \n                                    The MPS documentation recommends setting up EXCLUSIVE_PROCESS mode to ensure that a single \n                                    MPS server is using the GPU. However, this mode is not supported when the GPU is in MIG mode as we use multiple \n                                    MPS servers (one per MIG GPU instance).\n                                    \n                                  \n                              Follow the steps outlined in the previous sections to configure the desired MIG geometry on the GPU. For this example,\n                              we configure the GPU into a 3g.20gb,3g.2gb geometry: \n                              \n                            \n                              In this step, we start an MPS control daemon (with admin privileges) and ensure we use a different socket for each daemon:\n                              \n                            \n                              Now we can launch the application by specifying the desired MIG device using CUDA_VISIBLE_DEVICES:\n                              \n                            \n                              We now provide a script below where we attempt to run the BlackScholes from before on the two MIG devices \n                              created on the GPU:\n                              \n                            \n                              When running this script, we can observe the two MPS servers on each MIG device and the corresponding CUDA program started\n                              as an \n                              MPS client when using nvidia-smi:\n                              \n                             \n                              NVIDIA Container Toolkit has been enhanced to provide support for MIG devices, allowing users to run \n                           GPU containers with runtimes such as Docker. This section provides an overview of running Docker containers on A100 with MIG.\n                           \n                         \n                              Many Linux distributions may come with Docker-CE pre-installed. \n                              If not, use the Docker installation script to install Docker. \n                              \n                            \n                              Now install the NVIDIA Container Toolkit (previously known as nvidia-docker2). \n                              MIG support is available starting with v2.3 of nvidia-docker2 (or v1.1.1 of the \n                              nvidia-container-toolkit package). \n                              \n                            \n                              To get access to the /dev nvidia capabilities, \n                              it is recommended to use at least v2.5.0 of nvidia-docker2. See the \n                              Installation Guide for more information.\n                              \n                            \n                              For brevity, the installation instructions provided here are for Ubuntu 18.04 LTS. \n                              Refer to the  \n                                 NVIDIA Container Toolkit page for instructions on other Linux distributions. \n                              \n                            \n                              Setup the repository and the GPG key:\n                              \n                            \n                              Install the NVIDIA Container Toolkit packages (and their dependencies):\n                              \n                            \n                              To run containers on specific MIG devices - whether these are GIs or specific underlying CIs, \n                              then the NVIDIA_VISIBLE_DEVICES variable (or the --gpus option \n                              with Docker 19.03+) can be used. \n                              \n                            MIG-<GPU-UUID>/<GPU instance ID>/<compute instance ID> \n                                       when using R450 and R460 drivers or MIG-<UUID> starting with \n                                       R470 drivers.\n                                       \n                                     GPUDeviceIndex>:<MIGDeviceIndex> \n                              If using Docker 19.03, the --gpus option can be used to specify MIG devices by \n                              using the following format: \u2018\u201cdevice=MIG-device\u201d\u2019, where MIG-device can follow \n                              either of the format specified above for NVIDIA_VISIBLE_DEVICES.\n                              \n                              \n                            \n                              The following example shows running nvidia-smi from within a CUDA container using both formats. \n                              As can be seen in the example, only one MIG device as chosen is visible to the container when using either format.\n                              \n                            \n                              A more complex example is to run a TensorFlow container to do a training run using GPUs on the MNIST dataset. This is shown\n                              below:\n                              \n                            MIG support in Kubernetes is available starting with v0.7.0 of the NVIDIA Device Plugin for Kubernetes.\n                           Visit the documentation \n                           on getting started with MIG and Kubernetes.\n                           \n                         Slurm is a \n                           workload manager that is widely used at high performance computing centers such as government labs, universities.\n                           \n                         \n                           Starting with 21.08, Slurm supports the usage of MIG devices. Refer to the official \n                           documentation \n                           on getting started. \n                           \n                         \n                        Currently, the NVIDIA kernel driver exposes its interfaces through a few system-wide device nodes. \n                        Each physical GPU is represented by its own device node - e.g. nvidia0, nvidia1 etc. \n                        This is shown below for a 2-GPU system.\n                        \n                      \n                        Starting with CUDA 11/R450, a new abstraction known as nvidia-capabilities has been introduced. \n                        The idea being that access to a specific capability is required to perform certain actions through the driver. If a user \n                        has access to the capability, the action will be carried out. If a user does not have access to the capability,\n                        the action will fail. The one exception being if you are the root-user (or any user with CAP_SYS_ADMIN privileges). \n                        With CAP_SYS_ADMIN privileges, you implicitly have access to all nvidia-capabilities.\n                        \n                      \n                        For example, the mig-config capability allows one to create and destroy MIG instances on any MIG-capable GPU \n                        (e.g. the A100 GPU). Without this capability, all attempts to create or destroy a MIG instance will fail. Likewise, the fabric-mgmt \n                        capability allows one to run the Fabric Manager as a non-root but privileged daemon. Without this capability, all attempts\n                        to launch the \n                        Fabric Manager as a non-root user will fail.\n                        \n                      \n                        The following sections walk through the system level interface for managing these new nvidia-capabilities, including the \n                        steps necessary to grant and revoke access to them.\n                        \n                      \n                           An example of loading the nvidia kernel module with this parameter set can be seen below:\n                           \n                         \n                           The system level interface for interacting with /dev based capabilities is actually through a combination of /proc and /dev.\n                           \n                         \n                           First, a new major device is now associated with nvidia-caps and can be read from the standard /proc/devices file.\n                           \n                         \n                           Second, the exact same set of files exist under /proc/driver/nvidia/capabilities. \n                           These files no longer control access to the capability directly and instead, the contents of \n                           these files point at a device node under /dev, through which \n                           cgroups can be used to control access to the capability.\n                           \n                         \n                           This can be seen in the example below:\n                           \n                         \n                           The combination of the device major for nvidia-caps and the value of DeviceFileMinor in this file indicate that the \n                           mig-config capability (which allows a user to create and destroy MIG devices) is controlled by the device node with a major:minor \n                           of 238:1. \n                           As such, one will need to use cgroups to grant a process read access to this device in order to configure MIG devices. The purpose of the DeviceFileMode \n                           and DeviceFileModify fields in this file are explained later on in this section.\n                           \n                         \n                           The standard location for these device nodes is under /dev/nvidia-caps as seen in the example below:\n                           \n                         \n                           Unfortunately, these device nodes cannot be automatically created/deleted by the NVIDIA driver at the same time it creates/deletes\n                           files underneath /proc/driver/nvidia/capabilities \n                           (due to GPL compliance issues). Instead, a user-level program called nvidia-modprobe is provided, that can be invoked from user-space in order to do this. For example:        \n                           \n                         nvidia-modprobe looks at the DeviceFileMode in each capability file and creates the device node with the permissions indicated \n                           (e.g. +ur from a value of 256 (o400) from our example for mig-config).\n                           \n                         \n                           Programs such as nvidia-smi will automatically invoke nvidia-modprobe (when available) to create these device nodes on your behalf. \n                           In other scenarios it is not necessarily required to use nvidia-modprobe to create these device nodes, but it does make the process simpler. \n                           \n                         \n                           If you actually want to prevent nvidia-modprobe from ever creating a particular device node on your behalf, you can do the following:\n                           \n                         \n                           You will then be responsible for managing creation of the device node referenced by /proc/driver/nvidia/capabilities/mig/config going forward. \n                           If you want to change that in the future, simply reset it to a value of \"DeviceFileModify: 1\" with the same command sequence.\n                           \n                         \n                           This is important in the context of containers because we may want to give a container access to a certain capability even\n                           if it doesn't exist in the /proc hierarchy yet.\n                           \n                         \n                           For example, granting a container the mig-config capability implies that we should also grant it capabilities to access all possible gis and cis that could be created \n                           for any GPU on the system. Otherwise the container will have no way of working with those gis and cis once they have actually\n                           been created.\n                           \n                         \n                           One final thing to note about /dev based capabilities is that the minor numbers for all possible capabilities are predetermined and can be \n                           queried under various files of the form:\n                           \n                         \n                           For example, all capabilities related to MIG can be looked up as:\n                           \n                         \n                           The format of the content follows: GPU<deviceMinor>/gi<GPU instance ID>/ci<compute instance ID> \n                              The NVML device numbering (e.g. through nvidia-smi) is not the device minor number.\n                              \n                            \n                           For example, if the MIG geometry was created as below:\n                           \n                          Then the corresponding device nodes: /dev/nvidia-cap12, /dev/nvidia-cap13 and \n                           /dev/nvidia-cap14 and /dev/nvidia-cap15 would be created.\n                           \n                         \n                           The system level interface for interacting with /proc based nvidia-capabilities is rooted at \n                           /proc/driver/nvidia/capabilities. Files underneath this hierarchy are used to represent each capability, with \n                           read access to these files controlling whether a user has a given capability or not. These files have no content and \n                           only exist to represent a given capability.\n                           \n                         \n                           For example, the mig-config capability (which allows a user to create and destroy MIG devices) is represented as follows:\n                           \n                         \n                           Likewise, the capabilities required to run workloads on a MIG device once it has been created are represented as follows \n                           (namely as access to the GPU Instance and Compute Instance that comprise the MIG device):\n                           \n                         \n                           And the corresponding file system layout is shown below with read permissions:\n                           \n                         \n                           For a CUDA process to be able to run on top of MIG, it needs access to the Compute Instance \n                           capability and its parent GPU Instance. Thus a MIG device is identified by the following format: \n                           \n                         \n                           As an example, having read access to the following paths would allow one to run workloads on the MIG device represented by\n                           \n                           <gpu0, gi0, ci0>:\n                           \n                         \n                           Note, that there is no access file representing a capability to run workloads on gpu0 (only on gi0 and ci0 that sit underneath\n                           gpu0). \n                           This is because the traditional mechanism of using cgroups to control access to top level GPU devices (and any required meta\n                           devices) is still required. \n                           As shown earlier in the document, the cgroups mechanism applies to:\n                           \n                         \n                           In the context of containers, a new mount namespace should be overlaid on top of the path for /proc/driver/nvidia/capabilities, and only those \n                           capabilities a user wishes to grant to a container should be bind-mounted in. Since the host\u2019s user/group information is retained across the bind-mount, \n                           it must be ensured that the correct user permissions are set for these capabilities on the host before injecting them into\n                           a container.\n                           \n                                     \nThis document is provided for information\n                                 purposes only and shall not be regarded as a warranty of a\n                                 certain functionality, condition, or quality of a product.\n                                 NVIDIA Corporation (\u201cNVIDIA\u201d) makes no representations or\n                                 warranties, expressed or implied, as to the accuracy or\n                                 completeness of the information contained in this document\n                                 and assumes no responsibility for any errors contained\n                                 herein. NVIDIA shall have no liability for the consequences\n                                 or use of such information or for any infringement of\n                                 patents or other rights of third parties that may result\n                                 from its use. This document is not a commitment to develop,\n                                 release, or deliver any Material (defined below), code, or\n                                 functionality. \nNVIDIA reserves the right to make corrections, modifications,\n                                 enhancements, improvements, and any other changes to this\n                                 document, at any time without notice. \nCustomer should obtain the latest relevant information before\n                                 placing orders and should verify that such information is\n                                 current and complete. \nNVIDIA products are sold subject to the NVIDIA standard terms and\n                                 conditions of sale supplied at the time of order\n                                 acknowledgement, unless otherwise agreed in an individual\n                                 sales agreement signed by authorized representatives of\n                                 NVIDIA and customer (\u201cTerms of Sale\u201d). NVIDIA hereby\n                                 expressly objects to applying any customer general terms and\n                                 conditions with regards to the purchase of the NVIDIA\n                                 product referenced in this document. No contractual\n                                 obligations are formed either directly or indirectly by this\n                                 document. \nNVIDIA products are not designed, authorized, or warranted to be\n                                 suitable for use in medical, military, aircraft, space, or\n                                 life support equipment, nor in applications where failure or\n                                 malfunction of the NVIDIA product can reasonably be expected\n                                 to result in personal injury, death, or property or\n                                 environmental damage. NVIDIA accepts no liability for\n                                 inclusion and/or use of NVIDIA products in such equipment or\n                                 applications and therefore such inclusion and/or use is at\n                                 customer\u2019s own risk. \nNVIDIA makes no representation or warranty that products based on\n                                 this document will be suitable for any specified use.\n                                 Testing of all parameters of each product is not necessarily\n                                 performed by NVIDIA. It is customer\u2019s sole responsibility to\n                                 evaluate and determine the applicability of any information\n                                 contained in this document, ensure the product is suitable\n                                 and fit for the application planned by customer, and perform\n                                 the necessary testing for the application in order to avoid\n                                 a default of the application or the product. Weaknesses in\n                                 customer\u2019s product designs may affect the quality and\n                                 reliability of the NVIDIA product and may result in\n                                 additional or different conditions and/or requirements\n                                 beyond those contained in this document. NVIDIA accepts no\n                                 liability related to any default, damage, costs, or problem\n                                 which may be based on or attributable to: (i) the use of the\n                                 NVIDIA product in any manner that is contrary to this\n                                 document or (ii) customer product designs. \nNo license, either expressed or implied, is granted under any NVIDIA\n                                 patent right, copyright, or other NVIDIA intellectual\n                                 property right under this document. Information published by\n                                 NVIDIA regarding third-party products or services does not\n                                 constitute a license from NVIDIA to use such products or\n                                 services or a warranty or endorsement thereof. Use of such\n                                 information may require a license from a third party under\n                                 the patents or other intellectual property rights of the\n                                 third party, or a license from NVIDIA under the patents or\n                                 other intellectual property rights of NVIDIA. \nReproduction of information in this document is permissible only if\n                                 approved in advance by NVIDIA in writing, reproduced without\n                                 alteration and in full compliance with all applicable export\n                                 laws and regulations, and accompanied by all associated\n                                 conditions, limitations, and notices. \nTHIS DOCUMENT AND ALL NVIDIA DESIGN SPECIFICATIONS, REFERENCE\n                                 BOARDS, FILES, DRAWINGS, DIAGNOSTICS, LISTS, AND OTHER\n                                 DOCUMENTS (TOGETHER AND SEPARATELY, \u201cMATERIALS\u201d) ARE BEING\n                                 PROVIDED \u201cAS IS.\u201d NVIDIA MAKES NO WARRANTIES, EXPRESSED,\n                                 IMPLIED, STATUTORY, OR OTHERWISE WITH RESPECT TO THE\n                                 MATERIALS, AND EXPRESSLY DISCLAIMS ALL IMPLIED WARRANTIES OF\n                                 NONINFRINGEMENT, MERCHANTABILITY, AND FITNESS FOR A\n                                 PARTICULAR PURPOSE. TO THE EXTENT NOT PROHIBITED BY LAW, IN\n                                 NO EVENT WILL NVIDIA BE LIABLE FOR ANY DAMAGES, INCLUDING\n                                 WITHOUT LIMITATION ANY DIRECT, INDIRECT, SPECIAL,\n                                 INCIDENTAL, PUNITIVE, OR CONSEQUENTIAL DAMAGES, HOWEVER\n                                 CAUSED AND REGARDLESS OF THE THEORY OF LIABILITY, ARISING\n                                 OUT OF ANY USE OF THIS DOCUMENT, EVEN IF NVIDIA HAS BEEN\n                                 ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. Notwithstanding\n                                 any damages that customer might incur for any reason\n                                 whatsoever, NVIDIA\u2019s aggregate and cumulative liability\n                                 towards customer for the products described herein shall be\n                                 limited in accordance with the Terms of Sale for the\n                                 product. NVIDIA and the NVIDIA logo are trademarks and/or registered trademarks of NVIDIA\n                                 Corporation in the Unites States and other countries. Other company and product\n                                 names may be trademarks of the respective companies with which they are\n                                 associated. \u00a9 2020-2024 NVIDIA Corporation & affiliates. All rights\n                                 reserved. Privacy Policy | \n                  Manage My Privacy | \n                  Do Not Sell or Share My Data | \n                  Terms of Service | \n                  Accessibility | \n                  Corporate Policies | \n                  Product Security | \n                  Contact", "https://docs.nvidia.com/deploy/cuda-compatibility/index.html": "CUDA Compatibility CUDA Compatibility describes the use of new CUDA toolkit components on systems with older base installations. The NVIDIA\u00ae CUDA\u00ae Toolkit enables developers to build NVIDIA GPU accelerated compute applications for desktop computers, enterprise, and data centers to hyperscalers. It consists of the CUDA compiler toolchain including the CUDA runtime (cudart) and various CUDA libraries and tools. To build an application, a developer has to install only the CUDA Toolkit and necessary libraries required for linking. In order to run a CUDA application, the system should have a CUDA enabled GPU and an NVIDIA display driver that is compatible with the CUDA Toolkit that was used to build the application itself. If the application relies on dynamic linking for libraries, then the system should have the right version of such libraries as well. Figure 1 Components of CUDA\uf0c1 Every CUDA toolkit also ships with an NVIDIA display driver package for convenience. This driver supports all the features introduced in that version of the CUDA Toolkit. Please check the toolkit and driver version mapping in the release notes. The driver package includes both the user mode CUDA driver (libcuda.so) and kernel mode components necessary to run the application. Typically, upgrading a CUDA Toolkit involves upgrading both the toolkit and the driver to get the bleeding edge toolkit and driver capabilities. Figure 2 CUDA Upgrade Path\uf0c1 But this is not always required. CUDA Compatibility guarantees allow for upgrading only certain components and that will be the focus of the rest of this document. We will see how the upgrade to a new CUDA Toolkit can be simplified to not always require a full system upgrade. From CUDA 11 onwards, applications compiled with a CUDA Toolkit release from within a CUDA major release family can run, with limited feature-set, on systems having at least the minimum required driver version as indicated below. This minimum required driver can be different from the driver packaged with the CUDA Toolkit but should belong to the same major release. Refer to the CUDA Toolkit Release Notes for the complete table. CUDA Toolkit Linux x86_64 Minimum Required Driver Version Windows Minimum Required Driver Version CUDA 12.x >=525.60.13 >=527.41 CUDA 11.x >= 450.80.02* >=452.39* CUDA 11.0 was released with an earlier driver version, but by upgrading to Tesla Recommended Drivers 450.80.02 (Linux) / 452.39 (Windows) as indicated, minor version compatibility is possible across the CUDA 11.x family of toolkits. While applications built against any of the older CUDA Toolkits always continued to function on newer drivers due to binary backward compatibility, before CUDA 11, applications built against newer CUDA Toolkit releases were not supported on older drivers without forward compatibility package. If you are using a new CUDA 10.x minor release, then the minimum required driver version is the same as the driver that\u2019s packaged as part of that toolkit release. Consequently, the minimum required driver version changed for every new CUDA Toolkit minor release until CUDA 11.1. Therefore, system administrators always have to upgrade drivers in order to support applications built against CUDA Toolkits from 10.x releases. CUDA Toolkit Linux x86_64 Minimum Required Driver Version Windows Minimum Required Driver Version CUDA 10.2 >= 440.33 >=441.22 CUDA 10.1 >= 418.39 >=418.96 CUDA 10.0 >= 410.48 >=411.31 With minor version compatibility, upgrading to CUDA 11.1 is now possible on older drivers from within the same major release family such as 450.80.02 that was shipped with CUDA 11.0, as shown below: Minimum required driver version guidance can be found in the CUDA Toolkit Release Notes. Note that if the minimum required driver version is not installed in the system, applications will return an error as shown below. Developers and system admins should note two important caveats when relying on minor version compatibility. If either of these caveats are limiting, then a new CUDA driver from the same minor version of the toolkit that the application was built with or later is required. Limited feature set Sometimes features introduced in a CUDA Toolkit version may actually span both the toolkit and the driver. In such cases an application that relies on features introduced in a newer version of the toolkit and driver may return the following error on older drivers: cudaErrorCallRequiresNewerDriver. As mentioned earlier, admins should then upgrade the installed driver also. Application developers can avoid running into this problem by having the application explicitly check for the availability of features. Refer to the CUDA Compatibility Developers Guide for more details. Applications using PTX will see runtime issues Applications that compile device code to PTX will not work on older drivers. If the application requires PTX then admins have to upgrade the installed driver. PTX Developers should refer to the CUDA Compatibility Developers Guide and PTX programming guide in the CUDA C++ Programming Guide for details on this limitation. As described, applications that directly rely only on the CUDA runtime can be deployed in the following two scenarios: CUDA driver that\u2019s installed on the system is newer than the runtime.\r\nCUDA runtime is newer than the CUDA driver on the system but they are from the same major release of CUDA Toolkit. In scenario 2, system admins should be aware of the aforementioned limitations and should be able to tell why an application may be failing if they run into any issues. Minor version compatibility has another benefit that offers flexibility in the use and deployment of libraries. Applications that use libraries that support minor version compatibility can be deployed on systems with a different version of the toolkit and libraries without recompiling the application for the difference in the library version. This holds true for both older and newer versions of the libraries provided they are all from the same major release family. Note that libraries themselves have interdependencies that should be considered. For example, each cuDNN version requires a certain version of cuBLAS. Figure 3 NVRTC supports minor version compatibility from CUDA 11.3 onwards\uf0c1 However, if an application is unable to leverage the minor version compatibility due to any of the aforementioned reasons, then the Forward Compatibility model can be used as an alternative even though Forward Compatibility is mainly intended for compatibility across major toolkit versions. Increasingly, data centers and enterprises may not want to update the NVIDIA GPU Driver across major release versions due to the rigorous testing and validation that happens before any system level driver installations are done. To support such scenarios, CUDA introduced a Forward Compatibility Upgrade path in CUDA 10.0. Figure 4 Forward Compatibility Upgrade Path\uf0c1 Forward Compatibility is applicable only for systems with NVIDIA Data Center GPUs or select NGC Server Ready SKUs of RTX cards. It\u2019s mainly intended to support applications built on newer CUDA Toolkits to run on systems installed with an older NVIDIA Linux GPU driver from different major release families. This new forward-compatible upgrade path requires the use of a special package called \u201cCUDA compat package\u201d. The CUDA compat package is available in the local installers or the CUDA network repositories provided by NVIDIA as cuda-compat-12.4. Install the package on the system using the package installer. On Ubuntu, for example: The compat package will then be installed to the versioned toolkit location typically found in the toolkit directory. For example, for 12.5 it will be found in /usr/local/cuda-12.5/. The cuda-compat package consists of the following files: libcuda.so.* - the CUDA Driver libnvidia-nvvm.so.* - JIT LTO ( CUDA 11.5 and later only) libnvidia-ptxjitcompiler.so.* - the JIT (just-in-time) compiler for PTX files libcudadebugger.so.* -GPU debugging support for CUDA Driver (CUDA 11.8 and later only) These files should be kept together as the CUDA driver is dependent on the libnvidia-ptxjitcompiler.so.* of the same version. Note This package only provides the files, and does not configure the system. Example: CUDA Compatibility is installed and the application can now run successfully as shown below. In this example, the user sets LD_LIBRARY_PATH to include the files installed by the cuda-compat-12-1 package. Check the files installed under /usr/local/cuda/compat: The user can set LD_LIBRARY_PATH to include the files installed before running the CUDA 12.1 application: The cuda-compat package files can also be extracted from the appropriate datacenter driver \u2018runfile\u2019 installers (.run) available in NVIDIA driver downloads. To do this: Download the latest NVIDIA Data Center GPU driver , and extract the .run file using option -x. Copy the four CUDA compatibility upgrade files, listed at the start of this section, into a user- or root-created directory. Follow your system\u2019s guidelines for making sure that the system linker picks up the new libraries. Note Symlinks under /usr/local/cuda/compat need to be created manually when using the runfile installer. CUDA forward compat packages should be used only in the following situations when forward compatibility is required across major releases. The CUDA compat package is named after the highest toolkit that it can support. If you are on the R470 driver but require 12.5 application support, please install the cuda-compat package for 12.5. But when performing a full system upgrade, when choosing to install both the toolkit and the driver, remove any forward compatible packages present in the system. For example, if you are upgrading the driver to 525.60.13 which is the minimum required driver version for the 12.x toolkits, then the cuda-compat package is not required in most cases. 11.x and 12.x applications will be supported due to backward compatibility and future 12.x applications will be supported due to minor-version compatibility. But there are feature restrictions that may make this option less desirable for your scenario - for example: Applications requiring PTX JIT compilation support. Unlike the minor-version compatibility that is defined between CUDA runtime and CUDA driver, forward compatibility is defined between the kernel driver and the CUDA driver, and hence such restrictions do not apply. In order to circumvent the limitation, a forward compatibility package may be used in such scenarios as well. NVIDIA Kernel Mode Driver - Production Branch CUDA Forward Compatible Upgrade 470.57.02+ (CUDA 11.4) 530.30.02+ (CUDA 12.1) 535.54.03+ (CUDA 12.2) 545.23.06+ (CUDA 12.3) 550.54.14+ (CUDA 12.4) 555.42.02+ (CUDA 12.5) 12-5 C X C X C Not required 12-4 C C Not required X 12-3 C C X X 12-2 C Not required X X 12-1 C X X X 12-0 C X X X 11-8 C X X X 11-7 C X X X 11-6 C X X X 11-5 C X X X 11-4 Not required X X X C - Compatible X - Not compatible Branches R525, R515, R510, R465, R460, R455, R450, R440, R418, R410, R396, R390 are end of life and are not supported targets for compatibility. New Feature Branches (such as 495.xx) are not supported targets for CUDA Forward Compatibility. Examples of how to read this table: The CUDA 12-4 compat package is \u201cC\u201dompatible with driver versions 470, 535. It is \u201cNot required\u201d for 550, as 12.4 was paired with 550 and therefore no extra packages are needed. The CUDA \u201c12-3\u201d release is not-compatible (\u201cX\u201d) with driver version 550 as it was released prior to the driver. Binaries created in 12.3 are still subject to the backwards compatibility guarantees described in this document. There are specific features in the CUDA driver that require kernel-mode support and will only work with a newer kernel mode driver. A few features depend on other user-mode components and are therefore also unsupported. CUDA Forward Compatible Upgrade CUDA - OpenGL/Vulkan Interop cuMemMap* set of functionalities System Base Installation: 525 (>=.60.04) Driver 12-x No Yes [1] System Base Installation: 450 (>=.80.02) Driver 11-x No Yes [1] [1] This relies on CU_DEVICE_ATTRIBUTE_HANDLE_TYPE_POSIX_FILE_DESCRIPTOR_SUPPORTED and CU_DEVICE_ATTRIBUTE_VIRTUAL_ADDRESS_MANAGEMENT_SUPPORTED, which should be queried if you intend to use the full range of this functionality. [2] Supported on Red Hat Enterprise Linux operating system version 8.1 or higher. In addition to the CUDA driver and certain compiler components, there are other drivers in the system installation stack (for example, OpenCL) that remain on the old version. The forward-compatible upgrade path is for CUDA only. A well-written application should use following error codes to determine if CUDA Forward Compatible Upgrade is supported. System administrators should be aware of these error codes to determine if there are errors in the deployment. CUDA_ERROR_SYSTEM_DRIVER_MISMATCH = 803. This error indicates that there is a mismatch between the versions of the display driver and the CUDA driver. CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE = 804. This error indicates that the system was upgraded to run with forward compatibility but the visible hardware detected by CUDA does not support this configuration. There are two models of deployment for the CUDA compat package. We recommend the use of the \u2018shared\u2019 deployment mode. Shared deployment: Allows sharing the same compat package across installed toolkits in the system. Download and extract the latest forward compatibility package with the highest toolkit version in its name. Using RPATH, or through LD_LIBRARY_PATH or through an automatic loader (for example, ld.so.conf), point to that package. This is the most recommended choice. The user can set LD_LIBRARY_PATH to include the files installed before running the CUDA 11.1 application: Per-application deployment: Individual applications can choose a package of their choice and place it as part of the Modules system tied to the toolkit and the libraries. Using the Modules system, the admin, or the user, can set up \u2018module\u2019 scripts for each version of each toolkit package, and then load the module script for the toolkit as needed. There is an important consideration to the per-application deployment approach: older forward compatibility packages are not supported on new driver versions. Therefore the module load scripts should proactively query the system for whether the compatibility package can be used before loading the files. This is especially critical if there was a full system upgrade. In the cases where the module script cannot use CUDA compatible upgrade, a fallback path to the default system\u2019s installed CUDA driver can provide a more consistent experience and this can be achieved using RPATH. The CUDA driver maintains backward compatibility to continue support of applications built on older toolkits. Using a compatible minor driver version, applications build on CUDA Toolkit 11 and newer are supported on any driver from within the corresponding major release. Using the CUDA Forward Compatibility package, system administrators can run applications built using a newer toolkit even when an older driver that does not satisfy the minimum required driver version is installed on the system. This forward compatibility allows the CUDA deployments in data centers and enterprises to benefit from the faster release cadence and the latest features and performance of CUDA Toolkit. CUDA compatibility helps users by: Faster upgrades to the latest CUDA releases: Enterprises or data centers with NVIDIA GPUs have complex workflows and require advance planning for NVIDIA driver rollouts. Not having to update the driver for newer CUDA releases can mean that new versions of the software can be made available faster to users without any delays. Faster upgrades of the CUDA libraries: Users can upgrade to the latest software libraries and applications built on top of CUDA (for example, math libraries or deep learning frameworks) without an upgrade to the entire CUDA Toolkit or driver. This is possible as these libraries and frameworks do not have a direct dependency on the CUDA runtime, compiler or driver. This section includes some FAQs related to CUDA compatibility. What is the difference between CUDA forward compatible upgrade and CUDA minor version compatibility? When should users use these features? Area CUDA Forward Compatible Upgrade CUDA Minor Version Compatibility Compatibility Across older drivers from different major release versions of CUDA. Across minor release versions of CUDA only. Between kernel driver and user mode CUDA driver. Between libraries or runtimes that link to the CUDA driver. When to use If you cannot upgrade the kernel driver but need to use the latest CUDA Toolkit. If you want to support newer applications on older drivers within the same major release family. GPUs supported 11.4 UMD (User Mode Driver) and later will extend forward compatibility support\r\nto select NGC Ready NVIDIA RTX boards. Prior to that forward compatibility will be supported only on NVIDIA Data Center cards. All GPU products supported OS distributions supported Linux only Windows, Linux Features supported Some features such as (CUDA-GL interop, Power 9 ATS, cuMemMap APIs) are not supported.\r\nThese features depend on a new kernel mode driver and thus are not supported.\r\nThese are explicitly called out in the documentation. All existing CUDA features (from older minor releases) work. Users may have to incorporate checks in\r\ntheir application when using new features in the minor release (that require a new driver) to ensure graceful errors. CUDA releases supported All CUDA releases supported through the lifetime of the datacenter driver branch. For example,\r\nR418 (CUDA 10.1) EOLs in March 2022 - so all CUDA versions released (including major releases) during this timeframe are supported. Only works within a \u2018major\u2019 release family (such as 12.0 through 12.x).\r\nCompatibility is not supported across major CUDA releases. Application includes PTX or uses NVRTC No additional workflow required. Users should use the new PTX static library to rebuild binaries. Refer to the workflow section for more details. Requires administrator involvement Depends on the deployment. Users can also set up LD_LIBRARY_PATH with the new libraries from the cuda-compat-* package. Not required. Note For mobile compatibility information, see CUDA Upgradable Package for Jetson. This applies to L4T only. Does CUDA forward compatible upgrades work intra-branch? Users can upgrade the kernel mode driver within the same branch. Sometimes this may require updating the cuda-compat* package. This use-case is supported only for drivers on LLB and LTS branches of driver for select GPUs. Which GPUs are supported by the driver? The CUDA compatible upgrade is meant to ease the management of large production systems for enterprise customers. 11.4 UMD (User Mode Driver) and later will extend forward compatibility support to select NGC Ready NVIDIA RTX boards. Prior to that forward compatibility will be supported only on NVIDIA Data Center cards.\r\nIt\u2019s important to note that HW support is defined by the kernel mode driver and as such, newer CUDA drivers on their own will not enable new HW support. Refer to the following table to determine which hardware is supported by your system. Hardware Generation Compute Capability CTK Support Latest Forward Compatibility Package Support Driver Current Minimum Driver in Support Maximum Driver Supported* Hopper 9.x 11.8 - current current 525.60.13+ latest NVIDIA Ampere GPU Arch. 8.x 11.0 - current 470.57.02 latest Turing 7.5 10.0 - current latest Volta 7.x 9.0 - current latest Pascal 6.x 8.0 - current latest Maxwell 5.x 6.5 - current latest Refer to CUDA Driver Lifecycle to find the latest supported driver. What\u2019s the minimum required driver version of a toolkit? Refer to the Release notes. The developer is using PTX code in the application and seeing some errors or issues. What should we do? PTX and application compatibility information can be found in Binary Compatibility. If we build our CUDA application using CUDA 11.0, can it continue to be used with newer NVIDIA drivers (such as CUDA 11.1/R455, 11.x etc.)? Or is it only the other way around? Drivers have always been backwards compatible with CUDA. This means that a CUDA 11.0 application will be compatible with R450 (11.0), R455 (11.1) and beyond. CUDA applications typically statically include all the libraries (for example cudart, CUDA math libraries such as cuBLAS, cuFFT) they need, so they should work on new drivers or CUDA Toolkit installations. In other words, since CUDA is backward compatible, existing CUDA applications can continue to be used with newer CUDA versions. What is the minimum CUDA 11.x driver that supports the CUDA minor version compatibility? The minimum driver version required is 450.80.02. What about new features introduced in minor releases of CUDA? How does a developer build an application using newer CUDA Toolkits (e.g. 11.x) work on a system with a CUDA 11.0 driver (R450)? By using new CUDA versions, users can benefit from new CUDA programming model APIs, compiler optimizations and math library features. A subset of CUDA APIs don\u2019t need a new driver and they can all be used without any driver dependencies. For example, async copy APIs introduced in 11.1 do not need a new driver. To use other CUDA APIs introduced in a minor release (that require a new driver), one would have to implement fallbacks or fail gracefully. This situation is not different from what is available today where developers use macros to compile out features based on CUDA versions. Users should refer to the CUDA headers and documentation for new CUDA APIs introduced in a release. There are some issues that admins can advise the application developers to accommodate in their code. Please refer to the Best Practices Guide for further information. Does CUDA compatibility work with containers? Yes. CUDA minor version compatibility and CUDA forward compatible upgrade both work when using either NGC Deep Learning Framework containers or using containers that are based on the official CUDA base images. The images include the CUDA compatible upgrade libraries and the NVIDIA Container Toolkit (nvidia-docker2) has logic to correctly load the required libraries. I\u2019m running an NGC container and see this error: \u201cThis container was built for NVIDIA Driver Release 450.51 or later, but version 418.126.02 was detected and compatibility mode is UNAVAILABLE.\u201d. What could be wrong? It is possible you are either running a wrong version of the NVIDIA driver on the system or your system does not have an NVIDIA Data Center GPU. This document is provided for information purposes only and shall not be regarded as a warranty of a certain functionality, condition, or quality of a product. NVIDIA Corporation (\u201cNVIDIA\u201d) makes no representations or warranties, expressed or implied, as to the accuracy or completeness of the information contained in this document and assumes no responsibility for any errors contained herein. NVIDIA shall have no liability for the consequences or use of such information or for any infringement of patents or other rights of third parties that may result from its use. This document is not a commitment to develop, release, or deliver any Material (defined below), code, or functionality. NVIDIA reserves the right to make corrections, modifications, enhancements, improvements, and any other changes to this document, at any time without notice. Customer should obtain the latest relevant information before placing orders and should verify that such information is current and complete. NVIDIA products are sold subject to the NVIDIA standard terms and conditions of sale supplied at the time of order acknowledgement, unless otherwise agreed in an individual sales agreement signed by authorized representatives of NVIDIA and customer (\u201cTerms of Sale\u201d). NVIDIA hereby expressly objects to applying any customer general terms and conditions with regards to the purchase of the NVIDIA product referenced in this document. No contractual obligations are formed either directly or indirectly by this document. NVIDIA products are not designed, authorized, or warranted to be suitable for use in medical, military, aircraft, space, or life support equipment, nor in applications where failure or malfunction of the NVIDIA product can reasonably be expected to result in personal injury, death, or property or environmental damage. NVIDIA accepts no liability for inclusion and/or use of NVIDIA products in such equipment or applications and therefore such inclusion and/or use is at customer\u2019s own risk. NVIDIA makes no representation or warranty that products based on this document will be suitable for any specified use. Testing of all parameters of each product is not necessarily performed by NVIDIA. It is customer\u2019s sole responsibility to evaluate and determine the applicability of any information contained in this document, ensure the product is suitable and fit for the application planned by customer, and perform the necessary testing for the application in order to avoid a default of the application or the product. Weaknesses in customer\u2019s product designs may affect the quality and reliability of the NVIDIA product and may result in additional or different conditions and/or requirements beyond those contained in this document. NVIDIA accepts no liability related to any default, damage, costs, or problem which may be based on or attributable to: (i) the use of the NVIDIA product in any manner that is contrary to this document or (ii) customer product designs. No license, either expressed or implied, is granted under any NVIDIA patent right, copyright, or other NVIDIA intellectual property right under this document. Information published by NVIDIA regarding third-party products or services does not constitute a license from NVIDIA to use such products or services or a warranty or endorsement thereof. Use of such information may require a license from a third party under the patents or other intellectual property rights of the third party, or a license from NVIDIA under the patents or other intellectual property rights of NVIDIA. Reproduction of information in this document is permissible only if approved in advance by NVIDIA in writing, reproduced without alteration and in full compliance with all applicable export laws and regulations, and accompanied by all associated conditions, limitations, and notices. THIS DOCUMENT AND ALL NVIDIA DESIGN SPECIFICATIONS, REFERENCE BOARDS, FILES, DRAWINGS, DIAGNOSTICS, LISTS, AND OTHER DOCUMENTS (TOGETHER AND SEPARATELY, \u201cMATERIALS\u201d) ARE BEING PROVIDED \u201cAS IS.\u201d NVIDIA MAKES NO WARRANTIES, EXPRESSED, IMPLIED, STATUTORY, OR OTHERWISE WITH RESPECT TO THE MATERIALS, AND EXPRESSLY DISCLAIMS ALL IMPLIED WARRANTIES OF NONINFRINGEMENT, MERCHANTABILITY, AND FITNESS FOR A PARTICULAR PURPOSE. TO THE EXTENT NOT PROHIBITED BY LAW, IN NO EVENT WILL NVIDIA BE LIABLE FOR ANY DAMAGES, INCLUDING WITHOUT LIMITATION ANY DIRECT, INDIRECT, SPECIAL, INCIDENTAL, PUNITIVE, OR CONSEQUENTIAL DAMAGES, HOWEVER CAUSED AND REGARDLESS OF THE THEORY OF LIABILITY, ARISING OUT OF ANY USE OF THIS DOCUMENT, EVEN IF NVIDIA HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. Notwithstanding any damages that customer might incur for any reason whatsoever, NVIDIA\u2019s aggregate and cumulative liability towards customer for the products described herein shall be limited in accordance with the Terms of Sale for the product. NVIDIA and the NVIDIA logo are trademarks or registered trademarks of NVIDIA Corporation in the U.S. and other countries. Other company and product names may be trademarks of the respective companies with which they are associated. \nPrivacy Policy\r\n|\r\nManage My Privacy\r\n|\r\nDo Not Sell or Share My Data\r\n|\r\nTerms of Service\r\n|\r\nAccessibility\r\n|\r\nCorporate Policies\r\n|\r\nProduct Security\r\n|\r\nContact\n \r\n  Copyright \u00a9 2018-2024, NVIDIA Corporation & affiliates. All rights reserved.\r\n \nLast updated on May 31, 2024.\r\n      ", "https://docs.nvidia.com/cupti/index.html": "The API reference for CUPTI, the CUDA Profiling Tools Interface.\nThe CUPTI API \nPrivacy Policy\n|\nManage My Privacy\n|\nDo Not Sell or Share My Data\n|\nTerms of Service\n|\nAccessibility\n|\nCorporate Policies\n|\nProduct Security\n|\nContact\n \u00a9 Copyright 2018-2024, NVIDIA Corporation & Affiliates. All rights reserved.\n      Last updated on July 16, 2024.\n      ", "https://docs.nvidia.com/gpudirect-storage/index.html": "\n      NVIDIA GPUDirect Storage Documentation - Last updated June 24, 2024 \n     \n Privacy Policy | Manage My Privacy | Do Not Sell or Share My Data | Terms of Service | Accessibility | Corporate Policies | Product Security | Contact Copyright \u00a9 2024 NVIDIA Corporation", "https://docs.nvidia.com/compute-sanitizer/index.html": "", "https://docs.nvidia.com/nsight-systems/index.html": "Archives Release notes and known issues. NVIDIA Nsight Systems installation guide. NVIDIA Nsight Systems user guide. Information on the NVIDIA Software License Agreement as well as third party software and tools used by Nsight Systems. Documentation for previous versions of the NVIDIA Nsight Systems. \u00a9 Copyright 2018-2024, NVIDIA Corporation & Affiliates. All rights reserved.\r\n      Last updated on May 21, 2024.\r\n      ", "https://docs.nvidia.com/nsight-compute/index.html": "Nsight Compute Developer Interfaces Training Release Information Copyright and Licenses Release notes, including new features and important bug fixes. Supported platforms and GPUs. List of known issues for the current release. Kernel Profiling Guide with metric types and meaning, data collection modes and FAQ for common problems. NVIDIA Nsight Compute User Interface (UI) manual. Information on all views, controls and workflows within the tool UI. Transitions guide for Visual Profiler. NVIDIA Nsight Compute Command Line Interface (CLI) manual. Information on workflows and options for the command line, including multi-process profiling and NVTX filtering. Transitions guide for Nvprof. User manual on customizing NVIDIA Nsight Compute tools or integrating them with custom workflows. Information on writing section files, rules for automatic result analysis and scripting access to report files. NVIDIA Nsight Compute Training resources. Find documentation for previous versions of NVIDIA Nsight Compute. Information on the NVIDIA Software License Agreement as well as third party software and tools used by Nsight Compute. \u00a9 Copyright 2018-2024, NVIDIA Corporation & Affiliates. All rights reserved.\n      Last updated on Jun 03, 2024.\n      ", "https://docs.nvidia.com/nsight-visual-studio-edition/index.html": "CUDA Debugger Reference Release Information Copyright and License Notices NVIDIA\u00ae Nsight\u2122 Visual Studio Edition is an application development environment which brings GPU computing into Microsoft Visual Studio. allows you to build and debug integrated GPU kernels and native CPU code as well as inspect the state of the CPU, GPU, and memory. See the latest features and updates for this version of NVIDIA Nsight Visual Studio Edition. This chapter walks you through the system requirements for NVIDIA Nsight Visual Studio Edition, and the steps you\u2019ll need to install and get started using the software. This section provides a walkthrough and tutorial for using the CUDA Debugger with NVIDIA Nsight Visual Studio Edition. This section details how to configure the properties of a CUDA project, launching the CUDA Debugger, and how to attach debugging to a running CUDA Process. In this section, learn more about how to control GPU execution, set GPU breakpoints, and use global freeze. In this section, learn more about how to use various state inspection features of the CUDA Debugger, such as specifying the debugger context, viewing memory and variables, using the CUDA Info View, and using the CUDA Warp Watch. In this section, learn more about advanced CUDA topics, such as PTX and SASS assembly debugging, as well as how to use the CUDA Memory Checker. Additional resources for learning more about working with NVIDIA Nsight Visual Studio Edition. Find documentation for previous versions of NVIDIA Nsight Visual Studio Edition. This document is the End User License Agreement (EULA) for NVIDIA Nsight Visual Studio Edition. This document contains specific license terms and conditions for NVIDIA Nsight Visual Studio Edition. By accepting this agreement, you agree to comply with all the terms and conditions applicable to the specific product(s) included herein. \u00a9 Copyright 2018-2024, NVIDIA Corporation & Affiliates. All rights reserved.\r\n      Last updated on Jul 08, 2024.\r\n      ", "https://developer.nvidia.com/cuda-toolkit-archive": "Previous releases of the CUDA Toolkit, GPU Computing SDK, documentation and developer drivers can be found using the links below. Please select the release you want from the list below, and be sure to check www.nvidia.com/drivers for more recent production drivers appropriate for your hardware configuration. Latest ReleaseCUDA Toolkit 12.5.1  (July 2024), Versioned Online Documentation Archived Releases  Learn more about the latest CUDA Toolkit and the CUDA Tools and Library Ecosystem", "https://www.nvidia.com/en-us/about-nvidia/privacy-policy/": "Effective date May 21, 2024 (Archived versions)  We promise to protect your privacy.   When we use the term \u201cNVIDIA\u201d we\u2019re referring collectively to NVIDIA Corp. in the United States and to our subsidiaries and affiliates globally. If you have an NVIDIA account or have signed up for our content with your email address, you may visit privacy.nvidia.com to exercise your privacy rights. Otherwise, you can contact us directly at privacy@nvidia.com. We use your NVIDIA account or your registered email address to verify your identity. We collect your information when you search for information, order products, request to download content, register for events or demos, or give us feedback. This helps us deliver what you ask for, communicate with you, and better understand what your interests are. It also enables us to improve our web experiences, products and services, and find others who may be interested in them.  See More See Less  We collect your information when you create an account with us for GeForce NOW, NGC, GTC, or other programs to service your account, communicate with you, and comply with regional laws.  See More See Less  We collect your information when you use NVIDIA software, including GeForce Experience, GeForce NOW, Graphics Delivery Network, software for NVIDIA SHIELD, and enterprise software for our cloud, data center, networking, and embedded systems products.This helps us optimize your experience, improve our products and services, and better communicate with you. In addition, when you use ad-supported services such as an ad-supported plan of GeForce NOW, we collect and share information to personalize advertisements for you.  See More See Less  We collect your information from publicly or commercially available sources such as attendance at events we sponsor, searches on the public internet, and data enrichment services. This helps us communicate with you more effectively and find others who are interested in our products and services.  See More See Less  AV and AI technologies require access to large volumes of high-quality data to learn how to perceive, classify, and navigate among people, objects, and scenes. We collect public images and other data through sensors on NVIDIA or partner-identified vehicles and in clearly disclosed public spaces\u2013as well as datasets collected by others\u2013to improve the safety and reliability of our AV and AI models. This data is never associated with any other product or service.  See More See Less  NVIDIA does not use, sell, or share \u201csensitive personal information\u201d as defined by California law. If you\u2019ve consented to receive marketing communications or recommendations, we share hashed details about your identity with third-party ad providers such as Google to serve interest-based ads to you and others. These hashed details may include your name, email, phone number, job title, organizational business affiliations, zip code, country, and social media handles. Your information is shared in hashed form only, which means that your details are irreversibly converted to a fixed-size string of characters such as \u201c0890f456684a70f1a9f1dbcee40c1fe847b76f338581a9a1d9202c76b1c175f4\u201d (which is the SHA-256 hash of \u201cNVIDIA\u201d). Sharing information in hashed form means that third-party ad providers can only identify you if they already have the information we have shared and have hashed it themselves to match the hashed version we are sharing. Sharing information in hashed form is a way of identifying information that both parties have without sharing the information itself. You can opt out of data sharing for interest-based advertising at any time by visiting our Privacy Center\u00a0or by enabling an opt-out preference signal. NVIDIA websites detect and respond to Global Privacy Control signals by disabling all Performance, Personalization, and Advertising cookies. If you have consented to marketing communications or recommendations you will need to log into our Privacy Center to disable sharing with third party advertisers. To enable this signal, download and use a browser or browser extension that supports the Global Privacy Control. If you visit any of our NVIDIA websites, we or our third-party partners collect information using cookies, web beacons, or log file information. Please see our Cookie Policy for more details. We take special care to protect the privacy of children, and our products and services are not targeted for use by children under the age of 13. We only collect data from children who are above the age of digital consent in their jurisdiction (e.g., at least 13 for the United States), or if we have express parental consent (e.g., for attendance at one of our conferences). We share some personal data of account holders under the age of 18 if sharing personal data is required for service functionality.\u00a0For example, if an account holder under the age of 18 is using NVIDIA services via one of our GeForce NOW Alliance partners, we share the account holder\u2019s operating system version, network type, games played, session time, ratings and feedback, error data, and a masked version of the account holder\u2019s IP address with that GeForce NOW Alliance Partner to enable service functionality. If an account holder under the age of 18 uses an ad-supported GeForce NOW plan, we share the account holder\u2019s IP address, country, platform, and game title for purposes of fraud prevention and ad frequency capping. We also share this information as well as age range for purposes of interest-based advertising if the account holder is 16 or older. Account holders below the age of 16 are opted out of interest-based advertising by default, and all account holders may opt out of interest-based advertising by visiting our Privacy Center. We employ reasonable technological safeguards to comply with local laws, and to prevent underage children from accessing areas of our services where personal information may be collected. For example, underage children are not allowed to participate in our user-to-user forums, subscribe to an email newsletter, or enter any of our sweepstakes or contests. Please contact us if you become aware that your child has provided us with personal data without your consent. NVIDIA is located in California, and in most cases we need to securely transfer and store your information in the United States. Transfers of personal data to the United States, and to or from NVIDIA, are made subject to the Standard Contractual Clauses which have been pre-approved by the European Commission and ensure appropriate data protection safeguards. In addition, NVIDIA\u00a0complies with the EU-U.S., Swiss-U.S., and UK Extension to the EU-U.S. Data Privacy Framework Principles and we are subject to enforcement by the U.S. Federal Trade Commission. This means we adhere to the\u00a0Data Privacy Framework Principles of notice, choice, and accountability for onward transfer, security, data integrity, purpose limitation, access, recourse, enforcement, and liability. We are the data controller, and we remain responsible for any of your personal information that is shared with third parties for processing on our behalf. NVIDIA has committed to cooperating with the panel established by the EU data protection authorities (DPAs) the Swiss Federal Data Protection and Information Commissioner (FDPIC), and the UK Information Commissioner\u2019s Office (ICO) with regard to unresolved Data Privacy Framework complaints concerning data transferred from the EU Switzerland, and the UK. Under certain conditions, you may invoke binding arbitration to resolve any complaint. We are subject to U.S. law, and we may be required to share data with U.S. law enforcement agencies. To learn more about the Data Privacy Framework, please visit https://www.dataprivacyframework.gov/. For more information regarding our Data Privacy Framework certification, please visit: https://www.dataprivacyframework.gov/s/participant-search. We retain your personal data for as long as our engagement with you continues (e.g., emails, website visits, logins, or event attendance). We erase customer and enterprise personal data if there has been no engagement with you for more than five years. We retain data collected from public spaces for as long as it continues to support our AV and AI projects. If you are a member of the public and wish to exercise any of your privacy rights, please contact us directly at privacy@nvidia.com. You may also exercise your right to erasure at any time. If you have an NVIDIA account or have signed up for our content with your email address, you may visit privacy.nvidia.com to exercise your privacy rights. Otherwise contact us directly at privacy@nvidia.com. If you have any questions, wish to contact an NVIDIA data protection officer in a specified region, or if you\u2019re an Authorized Agent seeking to make a request on behalf of a consumer under California\u2019s Consumer Privacy Act, please contact our Data Privacy Team. Email privacy@nvidia.com Mail ATTN: Data Privacy Team NVIDIA Corporation 2788 San Tomas Expressway Santa Clara, CA 95051  Updates to this policy will be posted at privacy.nvidia.com. Significant updates will be communicated by email.", "https://www.nvidia.com/en-us/about-nvidia/privacy-center/": "Our NVIDIA Privacy Policy explains what data we collect and what we do with it. We never sell your data.  If you have a registered NVIDIA account, you can change your privacy settings at any time. Manage My Email Preferences Manage My Account  Privacy Settings* Manage My Cookies Delete My Data Request My Data *\u00a0If you have a registered NVIDIA account, you can change your privacy settings at any time.", "https://www.nvidia.com/en-us/preferences/start/": "", "https://www.nvidia.com/en-us/about-nvidia/terms-of-service/": "Last Modified: February 5, 2024 PLEASE READ THESE TERMS CAREFULLY BEFORE USING THIS SITE.  These Terms of Service (these \"Terms\") govern your access to and use of www.nvidia.com, rapids.ai, nventures.ai and jetson-ai-lab.com and other NVIDIA operated websites where these Terms are linked, including any content, functionality, and services offered on or through such websites and/or their copies (collectively, the \"Site\"). The Site is provided by NVIDIA Corporation (\"NVIDIA\", \"our\" or \"us\") for informational purposes only, and you may use the Site only if you can form a legally binding contract with NVIDIA and only in compliance with these Terms and all applicable laws and regulations. These Terms apply to all persons who access or use the Site. By accessing or using the Site, or downloading any materials from the Site, you agree to be bound by these Terms and acknowledge that you have read and understood our Privacy Notice. If you do not agree to these Terms or the Privacy Notice, you may not access or use the Site or download any materials from it. THESE TERMS CONTAIN A MANDATORY INDIVIDUAL ARBITRATION AGREEMENT AND CLASS ACTION/JURY TRIAL WAIVER PROVISION THAT REQUIRE, WITH ONLY SPECIFIED EXCEPTIONS SET FORTH HEREIN OR UNLESS YOU OPT OUT PURSUANT TO THE INSTRUCTIONS HEREIN, THE EXCLUSIVE USE OF FINAL AND BINDING ARBITRATION ON AN INDIVIDUAL BASIS ONLY TO RESOLVE DISPUTES, RATHER THAN JURY TRIALS OR CLASS, COLLECTIVE, PRIVATE ATTORNEY GENERAL OR REPRESENTATIVE ACTIONS OR PROCEEDINGS. Information on (or linked to) the Site, other than statements or characterizations of historical fact, may contain forward-looking statements. These forward-looking statements are based on our current expectations, estimates and projections about our industry, management's beliefs and certain assumptions made by us. These forward-looking statements are subject to a number of significant risks and uncertainties and our actual results may differ materially. For a discussion of factors that could affect our future results and business, please refer to our Annual Report on Form 10-K, subsequent Quarterly Reports on Form 10-Q, recent Current Reports on Form 8-K, and other Securities and Exchange Commission filings. NVIDIA undertakes no obligation to revise or update any forward-looking statements.  \u00a9 2024 NVIDIA Corporation. All rights reserved. NVIDIA and the NVIDIA logo are trademarks and/or registered trademarks of NVIDIA Corporation in the U.S. and other countries. Other company and product names may be trademarks of the respective companies with which they are associated.  You may not use NVIDIA's trademarks without NVIDIA\u2019s prior written permission, and nothing in these Terms shall be construed as granting such permission. Fair use of NVIDIA's trademarks in advertising and promotion of NVIDIA products requires proper acknowledgment. Performance tests and ratings are measured using specific computer systems and/or components and reflect the approximate performance of NVIDIA products as measured by those tests. Any difference in system hardware or software design or configuration may affect actual performance. The materials at the Site are subject to copyright and other intellectual property and other proprietary rights of NVIDIA or its licensors and any unauthorized use of any materials at the Site may violate copyright, trademark, and other intellectual property or other rights and applicable laws. You may have the option to download one copy of the software and materials found on the Site (\"Materials\") on a single computer for your personal, non-commercial internal use only unless specifically licensed to do otherwise by NVIDIA in writing or as allowed by any license terms which accompany or are provided with individual Materials. This is a license, not a transfer of title. Use of the Site is subject to the following restrictions: you may not: (a) modify the Site or use them for any commercial purpose, or any public display, performance, sale or rental; (b) decompile, reverse engineer, or disassemble the Site except and only to the extent permitted by applicable law or unless specifically licensed to do otherwise by NVIDIA in writing or as allowed by any license terms which accompany or are provided with individual Materials; (c) remove any copyright or other proprietary notices from the Site; (d) transfer the Site to any other person or entity; (e) use the Site for any purpose that is unlawful or prohibited by these Terms; (f) use any robot, spider, scraper, crawler, data mining tool, data gathering or extraction tool, or any other automatic device, program, algorithm or methodology, or any similar or equivalent manual process, to access, acquire, copy or monitor any portion of the Site, or in any way reproduce or circumvent the navigational structure or presentation of the Site, to obtain or attempt to obtain any materials, documents or information though any means not purposely made available through the Site; (g) take any actions that impose an unreasonable or disproportionately large load on the infrastructure of the Site, or NVIDIA\u2019s systems or networks, or any systems or networks connected to the Site or to NVIDIA; (h) use any device, software or routine to interfere or attempt to interfere with the proper working of the Site or any transaction being conducted on the Site, or with any other person\u2019s use of the Site; (i) attempt to gain unauthorized access to any portion or feature of the Site, or any other systems or networks connected to the Site or to any NVIDIA server, or to any of the services offered on or through the Site, by hacking, password \"mining\" or any other illegitimate means; or (j) probe, scan or test the vulnerability of the Site or any network connected to the Site, nor breach the security or authentication measures on the Site or any network connected to the Site. You agree to prevent any unauthorized copying of the Site. You agree that a breach of this Section shall constitute a material breach of these Terms. The Site is copyrighted and is protected by worldwide copyright laws and treaty provisions. It may not be copied, reproduced, modified, published, uploaded, posted, transmitted, or distributed in any way, without NVIDIA's prior written permission. Except as expressly provided herein, NVIDIA and its suppliers do not grant any express or implied right to you under any patents, copyrights, trademarks, trade secret or any other intellectual property or proprietary right. NVIDIA and its affiliates respect the intellectual property of others. If you believe that your work has been copied in a way that constitutes copyright infringement, please follow our Notice and Procedure for Making Claims of Copyright Infringement.\u00a0  NVIDIA may terminate your access to and use of the Site at any time if NVIDIA determines in its sole discretion that you are in breach of these Terms or other terms which may be associated with your use of the Site. Upon termination, you will immediately destroy the Materials, and certify to NVIDIA that you have done so.  THE SITE AND OTHER CONTENT OFFERED ON OR THROUGH THE SITE ARE PROVIDED ON AN \"AS IS\" AND \"AS AVAILABLE BASIS\". TO THE MAXIMUM EXTENT PERMITTED BY APPLICABLE LAW, NVIDIA DISCLAIMS ALL WARRANTIES AND REPRESENTATIONS OF ANY KIND, WHETHER EXPRESS, IMPLIED OR STATUTORY, RELATING TO OR ARISING UNDER THIS AGREEMENT, INCLUDING, WITHOUT LIMITATION, THE WARRANTIES OF TITLE, NONINFRINGEMENT, MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, USAGE OF TRADE AND COURSE OF DEALING. \u00a0 NEITHER NVIDIA NOR ANY PERSON ASSOCIATED WITH NVIDIA MAKES ANY WARRANTY OR REPRESENTATION WITH RESPECT TO THE COMPLETENESS, ACCURACY, SECURITY, RELIABILITY, QUALITY OR AVAILABILITY OF THE SITE. WITHOUT LIMITING THE FOREGOING, NEITHER NVIDIA NOR ANYONE ASSOCIATED WITH NVIDIA REPRESENTS OR WARRANTS THAT THE SITE, ITS CONTENT OR ANY SERVICES OR ITEMS OBTAINED THROUGH THE SITE WILL BE ACCURATE, RELIABLE, ERROR-FREE OR UNINTERRUPTED, THAT DEFECTS WILL BE CORRECTED, THAT THE SITE OR THE SERVER THAT MAKES IT AVAILABLE IS FREE OF VIRUSES OR OTHER HARMFUL COMPONENTS OR THAT THE SITE OR ANY SERVICES OR ITEMS OBTAINED THROUGH THE SITE WILL OTHERWISE MEET YOUR NEEDS OR EXPECTATIONS. NVIDIA MAY MAKE CHANGES TO SITE OR TO THE PRODUCTS DESCRIBED THEREIN AT ANY TIME WITHOUT NOTICE, BUT MAKES NO COMMITMENT TO (AND HAS NO OBLIGATION TO) UPDATE THE SITE.  NVIDIA blogs may refer to software products and features in various stages of development or availability. NVIDIA software products and features will be offered if and when available. The information contained in a blog is provided on a non-binding basis, and does not create any guarantee or legal obligation to NVIDIA. The development, release, timing and terms for any software products or features may change for any reason at NVIDIA's sole discretion. NVIDIA will have no liability arising from or in connection with statements contained in a blog. TO THE MAXIMUM EXTENT PERMITTED BY APPLICABLE LAW, IN NO EVENT WILL NVIDIA OR ITS AFFILIATES, OR ITS OR THEIR LICENSORS, SERVICE PROVIDERS, EMPLOYEES, AGENTS, OFFICERS OR DIRECTORS BE LIABLE FOR ANY DAMAGES OF ANY KIND, UNDER ANY LEGAL THEORY, ARISING OUT OF OR IN CONNECTION WITH YOUR USE, OR INABILITY TO USE, THE SITE INCLUDING WITHOUT LIMITATION (I) INDIRECT, PUNITIVE, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES, OR (II) DAMAGES FOR THE (A) COST OF PROCURING SUBSTITUTE GOODS OR (B) LOSS OF PROFITS, REVENUES, USE, DATA OR GOODWILL ARISING OUT OF OR RELATED TO THIS AGREEMENT, WHETHER BASED ON BREACH OF CONTRACT, TORT (INCLUDING NEGLIGENCE), STRICT LIABILITY, OR OTHERWISE, AND EVEN IF NVIDIA HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES AND EVEN IF A PARTY'S REMEDIES FAIL THEIR ESSENTIAL PURPOSE. TO THE MAXIMUM EXTENT PERMITTED BY APPLICABLE LAW, NVIDIA\u2019S TOTAL CUMULATIVE AGGREGATE LIABILITY FOR ANY AND ALL LIABILITIES, OBLIGATIONS OR CLAIMS ARISING OUT OF OR RELATED TO THESE TERMS WILL NOT EXCEED ONE HUNDRED U.S. DOLLARS ($100). SOME JURISDICTIONS DO NOT ALLOW THE EXCLUSION OF AND/OR LIMITATIONS ON INCIDENTAL OR CONSEQUENTIAL DAMAGES, SO THE ABOVE EXCLUSIONS AND/OR LIMITATIONS MAY NOT APPLY TO YOU. THESE TERMS GIVE YOU SPECIFIC LEGAL RIGHTS, AND YOU MAY ALSO HAVE OTHER RIGHTS, WHICH VARY FROM JURISDICTION TO JURISDICTION. THE DISCLAIMERS, EXCLUSIONS, AND LIMITATIONS OF LIABILITY UNDER THESE TERMS WILL NOT APPLY TO THE EXTENT PROHIBITED BY APPLICABLE LAW. You agree to indemnify and hold harmless NVIDIA, its affiliates, licensors and service providers, and its and their respective officers, directors, employees, contractors, agents, licensors, suppliers, successors and assigns (\u201cIndemnified Parties\u201d) and, at NVIDIA\u2019s election, defend the Indemnified Parties from and against any claims or lawsuits, liabilities, damages, judgments, awards, losses, costs, expenses or fees (including reasonable attorneys' fees) arising out of or relating to your violation of these Terms or your use of the Site other than as expressly authorized in these Terms. The software and documentation (\u201cProtected Items\u201d) are \u201cCommercial product[s]\u201d or \u201cCommercial service[s]\u201d as those terms are defined at 48 C.F.R. \u00a7 2.101, consisting of \u201ccommercial computer software\u201d and \u201ccommercial computer software documentation\u201d as such terms are used in, respectively, 48 C.F.R. \u00a7 12.212 and 48 C.F.R. \u00a7\u00a7 227.7202 & 252.227-7014(a)(1).\u00a0 The Protected Items are developed at private expense and provided subject to these Terms.\u00a0 In no event will the U.S. Government acquire rights in Protected Items beyond those specified in 48 C.F.R. \u00a7 52.227-19(b)(1)-(2) or \u00a7 252.227-7013(c) except as expressly approved by NVIDIA in writing.  Any material, information or other communication you transmit or post to the Site (\"Communications\") will be considered non-confidential and non-proprietary. You are solely responsible for the Communications, and NVIDIA will have no obligations with respect to the Communications. NVIDIA and its designees will be free to copy, disclose, distribute, incorporate and otherwise use the Communications and all data, images, sounds, text, and other things embodied therein for any and all commercial or non-commercial purposes. You are prohibited from posting or transmitting to or from the Site any unlawful, threatening, libelous, defamatory, obscene, pornographic, or other material that would violate any law in any jurisdiction. Any Communication is shared voluntarily at your sole risk and you understand it can be read, collected, used, and modified by those with access to it and NVIDIA is not responsible for such Communications including (without limitation) your privacy rights, your proprietary rights, or your legal and regulatory compliance. You acknowledge that NVIDIA does not manage or control Communications that you upload, access, store, or distribute through NVIDIA servers, and accepts no responsibility or liability for that information regardless of whether such Communication is transmitted to or by you in breach of these Terms. You represent and warrant that you own or have sufficient rights to submit the Communications and to grant the foregoing rights, and the Communications do not infringe on anyone else\u2019s rights and will not violate any applicable law. The linked sites are not under the control of NVIDIA and NVIDIA is not responsible for the content of any linked site or any link contained in a linked site. NVIDIA reserves the right to terminate any link or linking program at any time. NVIDIA does not endorse companies or products to which it links and reserves the right to note as such on its web pages. If you decide to access any of the third party sites linked to the Site, you do this entirely at your own risk. READ THIS SECTION CAREFULLY BECAUSE IT REQUIRES THE PARTIES TO ARBITRATE THEIR DISPUTES AND LIMITS THE MANNER IN WHICH YOU CAN SEEK RELIEF FROM US. Governing Law All matters relating to the Site or these Terms and any Disputes (as defined below) will be governed in all respects by the laws of the United States and the laws of the State of Delaware, without respect to conflict of laws principles or the United Nations Convention on Contracts for the International Sale of Goods. The parties acknowledge that these Terms evidence a transaction involving interstate commerce. Notwithstanding the preceding sentences with respect to the substantive law governing these Terms, the Federal Arbitration Act (9 U.S.C. \u00a7\u00a7 1-16) (as it may be amended, \"FAA\") governs the interpretation and enforcement of the Binding Arbitration provision below and preempts all state laws (and laws of other jurisdictions) to the fullest extent permitted by applicable law. If the FAA is found to not apply to any issue that arises from or relates to the Binding Arbitration provision, then that issue will be resolved under and governed by the law of the U.S. state where you live (if applicable) or the jurisdiction mutually agreed upon in writing by the parties. The application of the United Nations Convention on Contracts for the International Sale of Goods is expressly excluded. You agree to submit to the exclusive personal jurisdiction of the federal and state courts located in Santa Clara County, California, for any actions for which we retain the right to seek injunctive or other equitable relief in a court of competent jurisdiction to prevent the actual or threatened infringement, misappropriation, or violation of our data security, intellectual property rights, or other proprietary rights, as set forth in the Binding Arbitration provision below, including any provisional relief required to prevent irreparable harm. You agree that the Santa Clara County, California is the proper and exclusive forum for any appeals of an arbitration award, or for trial court proceedings in the event that the Binding Arbitration provision below is found to be unenforceable. If there is a conflict between the English and any non-English versions of these Terms, you and NVIDIA agree that the English version of these Terms will govern to the extent not prohibited by local law in your jurisdiction. Informal Resolution If you or NVIDIA have any dispute, claim or controversy arising out of or relating to the Site or these Terms (\"Dispute\"), we each agree to work in good faith to resolve the Dispute informally. If you have a Dispute, you must first contact NVIDIA and give NVIDIA an opportunity to resolve it by contacting NVIDIA by mail at NVIDIA Corporation, ATTN: Legal, 2788 San Tomas Expressway, Santa Clara, California, 95051. Either you or NVIDIA may seek to have a Dispute resolved in small claims court if all the requirements of the small claims court are satisfied. Either you or NVIDIA may seek to have a Dispute resolved in small claims court in your county of residence or the small claims court in closest proximity to your residence at any time before an arbitrator is appointed, and you may also bring a Dispute in small claims court in the Superior Court of California, County of Santa Clara.\u00a0 Binding Arbitration You and NVIDIA agree all Disputes will be resolved by arbitration administered by the office of Judicial Arbitration and Mediation Services (\u201cJAMS\u201d) under its Comprehensive Arbitration Rules and Procedures then in effect for JAMS. If the amount of the Dispute is less than $10,000, then JAMS\u2019 Optional Expedited Arbitration Rules and Procedures will apply. The dispute (including whether the claims asserted are arbitrable) will be referred to and finally determined by arbitration in accordance with the JAMS International Arbitration Rules. If there is any conflict between this section and any procedural or other rules issued by the administrator, this section will control. Except as required by applicable law or court order, you and NVIDIA agree to maintain confidentiality (and request the arbitrator to maintain confidentiality) of all aspects and outcomes of the arbitration, except a party may disclose information regarding the arbitration to (i) enforce this clause or an arbitration award or (ii) seek provisional remedies from a court of competent jurisdiction. The arbitrator will issue a written award and statement of decision describing the essential findings and conclusions on which the award is based, including the calculation of any damages awarded. The arbitrator will not have authority to award damages greater than the amount, or other than the types, allowed by this Agreement. Judgment on the award of the arbitrator may be entered by any court of competent jurisdiction. You and NVIDIA agree the arbitration award will be final and binding without appeal or review except as permitted by governing law. The arbitration proceedings will take place in Santa Clara County, California and be conducted in English. You and NVIDIA agree nothing in this section will limit the right of either party to apply for injunctive remedies or an equivalent type of urgent legal relief in any jurisdiction. If this arbitration provision is found to be void, unenforceable, or unlawful, in whole or in part, the void, unenforceable, or unlawful provision, in whole or in part, shall be severed. Severance of the void, unenforceable, or unlawful provision, in whole or in part, shall have no impact on the remaining provisions of the arbitration provision, which shall remain in force, or the parties' ability to compel arbitration of any remaining claims on an individual basis pursuant to the arbitration. Notwithstanding the foregoing, if the Class Action, Representative Action & Jury Trial Waiver below is found to be void, unenforceable, or unlawful, in whole or in part, because it would prevent you from seeking public injunctive relief, then any dispute regarding the entitlement to such relief (and only that relief) must be severed from arbitration and may be litigated in a civil court of competent jurisdiction. All other claims for relief subject to arbitration under this arbitration provision shall be arbitrated under its terms, and the parties agree that litigation of any dispute regarding the entitlement to public injunctive relief shall be stayed pending the outcome of any individual claims in arbitration. Class Action, Representative Action & Jury Trial Waiver WITH RESPECT TO ALL PERSONS AND ENTITIES, REGARDLESS OF WHETHER THEY HAVE OBTAINED OR USED THE SITE FOR PERSONAL, COMMERCIAL OR OTHER PURPOSES, ALL DISPUTES MUST BE BROUGHT IN THE PARTIES' INDIVIDUAL CAPACITY, AND NOT AS A PLAINTIFF OR CLASS MEMBER IN ANY PURPORTED CLASS ACTION, COLLECTIVE ACTION, PRIVATE ATTORNEY GENERAL ACTION OR OTHER REPRESENTATIVE PROCEEDING. THIS WAIVER APPLIES TO CLASS ARBITRATION, AND, UNLESS NVIDIA AGREES OTHERWISE, THE ARBITRATOR MAY NOT CONSOLIDATE MORE THAN ONE PERSON'S DISPUTES. YOU AND NVIDIA AGREE THAT THE ARBITRATOR MAY AWARD RELIEF ONLY TO AN INDIVIDUAL CLAIMANT AND ONLY TO THE EXTENT NECESSARY TO PROVIDE RELIEF ON INDIVIDUAL DISPUTE(S). ANY RELIEF AWARDED MAY NOT AFFECT OTHER USERS. YOU AND NVIDIA AGREE THAT, BY ENTERING INTO THESE TERMS, YOU AND NVIDIA ARE EACH WAIVING THE RIGHT TO A TRIAL BY JURY OR TO PARTICIPATE IN A CLASS ACTION, COLLECTIVE ACTION, PRIVATE ATTORNEY GENERAL ACTION, OR OTHER REPRESENTATIVE PROCEEDING OF ANY KIND. Right to Opt-Out You may opt-out of the foregoing jury trial, class action, arbitration, and collective or consolidated proceeding waiver provisions by notifying NVIDIA in writing within 30 days of commencement of use of the Site or within 30 days of any future change NVIDIA may make to the arbitration provisions in these Terms. Such written notification must be sent by mail to NVIDIA Corporation, Attn: Legal, 2788 San Tomas Expressway, Santa Clara, California, 95051 and must include (1) your name, (2) your address, (3) the reference to NVIDIA\u2019s website as the service to which the notice relates, and (4) a clear statement indicating that you do not wish to resolve disputes through arbitration and demonstrating compliance with the 30-day time limit to opt-out. Any opt-out notification received after the opt-out deadline or not including the required items noted in (1)-(4) in the preceding sentence will not be valid and you will be required to pursue your Dispute in arbitration or small claims court. Opting out of this dispute resolution procedure will not affect the terms and conditions of these Terms, which still apply to you. If you opt-out of any future change NVIDIA may make to the arbitration provisions in these Terms, the most recent version of such change before the change you rejected will apply. This Site is controlled by NVIDIA from its offices within the United States of America. NVIDIA makes no representation that the Site is appropriate or available for use in other locations, and access to them from territories where their content is illegal is prohibited. If you choose to access the Site from other locations you do so on your own initiative and are responsible for compliance with all applicable local laws. You may not use or export the Materials in violation of U.S. export laws and regulations.  NVIDIA may revise these Terms at any time by updating this posting. You should visit this page from time to time to review the then-current Terms because they are binding on you, and any use of the Site constitutes acceptance of the terms contained herein. Certain provisions of these Terms may be superseded by expressly designated legal notices or terms located on particular pages at the Site.", "https://www.nvidia.com/en-us/about-nvidia/accessibility/": "NVIDIA strives to provide individuals with disabilities access to its products and services, including through an accessible website. If you have questions, comments, or encounter any difficulty in using this site, please e-mail accessibility@nvidia.com or call +1 (408) 486-2000.", "https://www.nvidia.com/en-us/about-nvidia/company-policies/": "Sound ethics guide our business. To confidentially report a concern, visit our Speak Up Line. \u00a0 For a list of charters and documents relevant to NVIDIA\u2019s Board of Directors, visit our Investor website\u2019s Governance\u00a0page. We may make changes to our Online Privacy Policy from time to time. Please review our policies regularly as updated policies will apply to your future visits to our website. Select your preferred language.", "https://www.nvidia.com/en-us/product-security/": "NVIDIA takes security concerns seriously and works to quickly evaluate and address them. Once a security concern is reported, NVIDIA commits the appropriate resources to analyze, validate and provide corrective actions to address the issue. Below is a list of published NVIDIA Security Bulletins and Notices. NVIDIA recommends following the guidance given in these bulletins regarding driver or software package updates, or specified mitigations. Older Security Bulletins and Notices (prior to 2018) have been moved and may be found in the Security Bulletin Archive page. Customers are advised to subscribe to notifications to stay informed of initial release or major revisions to NVIDIA Security Bulletins. You may subscribe to receive email notifications here. For more search results, including Security Bulletins, click here Please use the form below to subscribe to email notifications on future NVIDIA Security Bulletins or Security Notices NVIDIA Privacy Policy", "https://www.nvidia.com/en-us/contact/": "Get help with your existing NVIDIA products and services. Connect with an NVIDIA Sales Representative and get purchase info. Find experienced, professional partners. More than 50 offices worldwide. 2788 San Tomas Expressway Santa Clara, CA 95051 View Directions Map View Campus Map Tel: +1 (408) 486-2000 info@nvidia.com Investor Inquiries: (877) 7-NVIDIA Product Support: Visit our Support page or chat with a Customer Care agent. Brazil S\u00e3o Paulo, SP Canada Toronto, Ontario U.S. Alabama Madison  California Palo Alto Santa Clara San Dimas Sunnyvale  Colorado Boulder  Illinois Champaign  Massachusetts Westborough Westford   Missouri St. Louis  New Jersey Holmdel  New York New York  North Carolina Durham  Oregon Hillsboro  Texas Austin  Utah Salt Lake City  Virginia Charlottesville Herndon  Washington Redmond Seattle  To confidentially report a concern, visit our Speak Up Line."}